{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/BDG_LOGO.png\" alt=\"drawing\" align=\"right\" width=\"200\"/>\n",
    "\n",
    "# H2020 RIA BigDataGrapes - Predictive Data Analytics (T4.3)\n",
    "\n",
    "### This jupyter notebook is described in the deliverable D4.3 (Pilot 4). \n",
    "### In this pilot, we investigate how the biological activity depends on the location of the vineyard, the agriculture practices followed, the extraction method used, and the variety of the grape. The data collected from the natural cosmetics pilot provides the necessary information for the evaluation of the quality of each sample, linked with the special characteristics of the vineyard of origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\u001b[0m\n",
      "Requirement already satisfied: scipy in /root/.local/lib/python2.7/site-packages (1.2.3)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy) (1.16.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b1Sj1ZdEr__J"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pandas",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ae791deb1d37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named pandas"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "1. year_of_analysis: inform for what year the analysis will be performed.\n",
    "2. type analysis: which Biological Activity (BA): Marceration or Ultrasound.\n",
    "3. satellite_source: which satellite source has been used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_of_analysis = 2018\n",
    "type_analysis = 'Maceration' # Biological Activity (BA): Maceration or Ultrasound\n",
    "satellite_source = 'sentinel2' # Source: 'sentinel2' or 'landsat8'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XaD-ZqcIxa1t"
   },
   "source": [
    "## Loading Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/maceration_ultrasound/sample.pickle', 'rb') as file:\n",
    "    exclude_sample = [142335]\n",
    "    \n",
    "    dict_sample = pickle.load(file)\n",
    "    df_samples = dict_sample[str(year_of_analysis)]\n",
    "\n",
    "    # filter the ones without a parcel_id\n",
    "    df_samples = df_samples[df_samples['geocledian_id'].isna() == False]\n",
    "    df_samples = df_samples[df_samples['geocledian_id'].isin(exclude_sample) == False]\n",
    "    df_samples['geocledian_id'] = df_samples['geocledian_id'].astype(int)\n",
    "\n",
    "print(len(df_samples))\n",
    "df_samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Maceration or Ultrasound Data\n",
    "\n",
    "The Biologic Activity data, wich can be Maceration and Ultrasound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a file, where you stored the pickled data\n",
    "with open('../datasets/maceration_ultrasound/ba_results_2018.pickle', 'rb') as file:\n",
    "\n",
    "    dict_ba = pickle.load(file)\n",
    "    df_ba = dict_ba[type_analysis]\n",
    "    \n",
    "    # drop some columns\n",
    "    df_ba.drop(\"Total microbial count\", axis=1, inplace=True)\n",
    "    df_ba.drop(\"Toxicity on skin cells (MTT assay)\", axis=1, inplace=True)\n",
    "    df_ba.drop(\"Gene expression (SIRT1) on skin cells\", axis=1, inplace=True)\n",
    "    df_ba.drop(\"Yeasts and moulds\", axis=1, inplace=True)\n",
    "    df_ba.drop(\"year\", axis=1, inplace=True)\n",
    "\n",
    "    list_of_maceration_properties = df_ba.columns\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging: Maceration & Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map = df_samples[['geocledian_id', 'sample_id']]\n",
    "df_ba = df_ba.merge(df_map, left_on=\"Sample_Id\", right_on=\"sample_id\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fk_wdp6Cxgnm"
   },
   "source": [
    "## Loading Parcels Satellite Data\n",
    "\n",
    "Satellite Imagery data, more specifically the vegetation indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "id": "7WD1Y6TXsDw9",
    "outputId": "bc18aa66-139b-42cb-b086-b8a6280a7ab6"
   },
   "outputs": [],
   "source": [
    "\n",
    "def adjust_dataframe_float_types(df, column_name):\n",
    "    df[column_name].replace('None', np.nan, inplace=True)\n",
    "    return df[column_name].astype('float64')\n",
    "\n",
    "\n",
    "columns = [\"key\", \"key_name\", \"source\", \"product\", \"parcel_id\", \"date\", \"min\", \"max\", \"mean\", \"std\", \"count\", \"sum\", \"index\"]\n",
    "df_parcels = pd.read_csv('../datasets/agknow/agknow_timeseries_BDG_apikey.csv', sep=';', names=columns, parse_dates=['date'])\n",
    "\n",
    "for col_name in ['max', 'min', 'mean', 'std', 'count', 'sum']: \n",
    "    df_parcels[col_name] = adjust_dataframe_float_types(df_parcels, col_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging: Maceration Data & Geocledian Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_parcel_ids = list(df_parcels['parcel_id'].unique())\n",
    "lst_maceration_parcel_ids = df_ba['geocledian_id'].tolist()\n",
    "\n",
    "df_ba = df_ba[df_ba[\"geocledian_id\"].isin(list_of_parcel_ids)]\n",
    "df_parcels = df_parcels[df_parcels['parcel_id'].isin(lst_maceration_parcel_ids)]\n",
    "\n",
    "list_of_parcel_ids = list(df_parcels['parcel_id'].unique())\n",
    "list_of_product_types = list(df_parcels['product'].unique())\n",
    "\n",
    "print (list_of_parcel_ids)\n",
    "print (list_of_product_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Indexes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index: Samples to parcels, parcels to samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_samples\n",
    "sample_to_parcel = {}\n",
    "parcel_to_sample = {}\n",
    "\n",
    "for idx, r in df_samples[[\"sample_id\", \"geocledian_id\"]].iterrows():\n",
    "    sample_to_parcel[str(r[\"sample_id\"])] = str(r[\"geocledian_id\"])\n",
    "    parcel_to_sample[str(r[\"geocledian_id\"])] = str(r[\"sample_id\"])\n",
    "\n",
    "print(\"sample_to_parcel\", sample_to_parcel)\n",
    "print(\"parcel_to_sample\", parcel_to_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index: Parcel_id to Crop_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcel_date_crop_dict = {}\n",
    "\n",
    "for parcel_id in list_of_parcel_ids:\n",
    "    date_crop = df_samples[df_samples[\"geocledian_id\"] == parcel_id][\"Sample collection day\"].max()\n",
    "    \n",
    "    date_crop = datetime.datetime(date_crop.year, date_crop.month, date_crop.day)\n",
    "    parcel_date_crop_dict[parcel_id] = date_crop\n",
    "\n",
    "parcel_date_crop_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index: BA_property -> [Property_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ba_property_dict():\n",
    "\n",
    "    maceration_property_dict = {}\n",
    "\n",
    "    for prop in list_of_maceration_properties:\n",
    "        if prop in ['Sample', 'Sample_Id']:\n",
    "            continue\n",
    "        maceration_property_dict[prop] = []\n",
    "        for parcel_id in list_of_parcel_ids:\n",
    "            sample_id = parcel_to_sample[str(parcel_id)]\n",
    "            df_parcel_maceration = df_ba[df_ba['sample_id'] == sample_id]\n",
    "            maceration_property_dict[prop].append(float(df_parcel_maceration[prop]))\n",
    "\n",
    "    # print(maceration_property_dict)\n",
    "    return maceration_property_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index: Parcel_id -> Agg_function -> [product_type value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " \n",
    "def get_product_type_signals_dict(agg_value_column, agg_time_function, satellite_source):\n",
    "    product_type_signals_dict = {}\n",
    "\n",
    "    for product_type in list_of_product_types:\n",
    "        if product_type == 'variations':\n",
    "            continue\n",
    "\n",
    "        product_type_signals_dict[product_type] = []\n",
    "        for parcel_id in list_of_parcel_ids:\n",
    "            # properties filter\n",
    "            df_parcels_filtered = df_parcels[(df_parcels['parcel_id'] == parcel_id) & (df_parcels['product'] == product_type) & (df_parcels['source'] == satellite_source)]\n",
    "            # exclude non\n",
    "            df_parcels_filtered = df_parcels_filtered[df_parcels_filtered[agg_value_column].notna()]\n",
    "            # getting the start and the end dates\n",
    "            \n",
    "            # if theere is no information to compute \n",
    "            if len(df_parcels_filtered) == 0:\n",
    "                # continue\n",
    "                raise Exception (\"Error: No parcel values!\")\n",
    "            \n",
    "            df_parcels_filtered = agg_time_function([parcel_id, df_parcels_filtered, agg_value_column])\n",
    " \n",
    "            # series \n",
    "            se_product_type_agg_value = df_parcels_filtered[agg_value_column]\n",
    "            se_product_type_agg_value = pd.to_numeric(pd.Series(se_product_type_agg_value), errors='coerce')\n",
    "            product_type_signals_dict[product_type].append(se_product_type_agg_value.mean())\n",
    "\n",
    "    return product_type_signals_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index - Maceration/Ultrasound Property Abreviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict_abreviation_maceration_property = {\n",
    "    'TFC': 'Total flavonoid content, TFC (μg/mL quercetin)',\n",
    "    'ABTS': 'Antioxidant activity ABTS (μg/mL trolox)',\n",
    "    'Refractive': 'Refractive Index %',\n",
    "    'TPC': 'Total phenolic content, TPC (μg/mL gallic acid)',\n",
    "    'pH':'pH',\n",
    "    'DPPH': 'Antioxidant activity DPPH (μg/mL trolox)'     \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Matrix Function\n",
    "\n",
    "The coefficient returns a value between -1 and 1 that represents the limits of correlation from a full negative correlation to a full positive correlation. \n",
    "* A value of 0 means no correlation;\n",
    "* The value must be interpreted, where often a value below -0.5 or above 0.5 indicates a notable correlation;\n",
    "* Values below those values suggest a less notable correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fn_correlation_matrix(agg_value_column, agg_time_function, satellite_source, verbose=False):\n",
    "    \n",
    "    product_type_signals_dict = get_product_type_signals_dict(agg_value_column, agg_time_function, satellite_source)\n",
    "    ba_property_dict = get_ba_property_dict()\n",
    "    \n",
    "    # build the correlation matrix\n",
    "    correlation_matrix = np.ones((len(ba_property_dict.keys()), len(product_type_signals_dict.keys())), dtype=np.float64)\n",
    "    \n",
    "    for i, observed_variable in enumerate(ba_property_dict.keys()):\n",
    "        for j, current_signal in enumerate(product_type_signals_dict.keys()):\n",
    "            np_observed_array = np.array(ba_property_dict[observed_variable])\n",
    "            np_signal_array = np.array(product_type_signals_dict[current_signal])\n",
    "            \n",
    "            # np.corrcoef: returns pearson product-moment correlation coefficients.\n",
    "            current_correlation = np.corrcoef(np_observed_array, np_signal_array)[0,1]\n",
    "            correlation_matrix[i][j] = current_correlation\n",
    "            if verbose: \n",
    "                print(\"correlation between {} and {} {}: {}\".format(observed_variable, current_signal, agg_value_column, current_correlation))    \n",
    "    \n",
    "    \n",
    "    y_labels = ['TFC', 'ABTS', 'Refractive', 'TPC', 'pH', 'DPPH'] # maceration_property_dict.keys()\n",
    "    x_labels = product_type_signals_dict.keys()\n",
    "    \n",
    "    return correlation_matrix, x_labels, y_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliar functions: Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import relativedelta\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def plot_heat_map(correlation_matrix, x_labels, y_labels, title, plot_shape, idx_plot):        \n",
    "    plt.subplot(plot_shape[0], plot_shape[1],idx_plot)\n",
    "    ax = sns.heatmap(correlation_matrix, linewidth=0.5, center=0, cmap=\"RdBu\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_yticklabels(y_labels, rotation=0, fontsize=\"10\", va=\"center\")\n",
    "    ax.set_xticklabels(x_labels, rotation=0, fontsize=\"10\", va=\"center\")\n",
    "\n",
    "\n",
    "def get_the_most_correlated_variables(correlation_matrix, x_labels, y_labels):\n",
    "    abs_matrix = np.abs(correlation_matrix)\n",
    "    max_corr_idx = np.argmax(abs_matrix, axis=1)\n",
    "    results = []\n",
    "\n",
    "    for i,idx_max in enumerate(max_corr_idx):\n",
    "        item = (y_labels[i], list(x_labels)[idx_max], correlation_matrix[i][idx_max], abs_matrix[i][idx_max])\n",
    "        results.append(item)\n",
    "\n",
    "    df = pd.DataFrame(results,  columns=[type_analysis,'Product_Type','Highest_Corr_Value','Highest_Corr_Value_Abs'])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time aggregation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def interval_from_the_begging_of_the_year_until_march(params_list, verbose=False):\n",
    "    parcel_id = params_list[0]\n",
    "    df_timeseries = params_list[1]\n",
    "    \n",
    "    date_crop = parcel_date_crop_dict[parcel_id]\n",
    "    date_end = datetime.datetime(date_crop.year, month=3, day=31)\n",
    "    date_start = datetime.datetime(date_crop.year, month=1, day=1)\n",
    "    \n",
    "    # temporal filter\n",
    "    df_filtered = df_timeseries[(df_timeseries.date >= date_start) & (df_timeseries.date <= date_end)]\n",
    "    \n",
    "    if verbose:\n",
    "        print (\"parcel_id {} start {} end {} crop {} len {}\".format(parcel_id, date_start.strftime(\"%d-%m-%Y\"), date_end.strftime(\"%d-%m-%Y\"), date_crop.strftime(\"%d-%m-%Y\"), len(df_filtered)))\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "def interval_from_the_begging_of_the_year_until_april(params_list, verbose=False):\n",
    "    parcel_id = params_list[0]\n",
    "    df_timeseries = params_list[1]\n",
    "    \n",
    "    date_crop = parcel_date_crop_dict[parcel_id]\n",
    "    date_end = datetime.datetime(date_crop.year, month=4, day=30)\n",
    "    date_start = datetime.datetime(date_crop.year, month=1, day=1)\n",
    "    \n",
    "    # temporal filter\n",
    "    df_filtered = df_timeseries[(df_timeseries.date >= date_start) & (df_timeseries.date <= date_end)]\n",
    "    \n",
    "    if verbose:\n",
    "        print (\"parcel_id {} start {} end {} crop {} len {}\".format(parcel_id, date_start.strftime(\"%d-%m-%Y\"), date_end.strftime(\"%d-%m-%Y\"), date_crop.strftime(\"%d-%m-%Y\"), len(df_filtered)))\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "def interval_from_the_begging_of_the_year_until_may(params_list, verbose=False):\n",
    "    parcel_id = params_list[0]\n",
    "    df_timeseries = params_list[1]\n",
    "    \n",
    "    date_crop = parcel_date_crop_dict[parcel_id]\n",
    "    date_end = datetime.datetime(date_crop.year, month=5, day=31)\n",
    "    date_start = datetime.datetime(date_crop.year, month=1, day=1)\n",
    "    \n",
    "    # temporal filter\n",
    "    df_filtered = df_timeseries[(df_timeseries.date >= date_start) & (df_timeseries.date <= date_end)]\n",
    "    \n",
    "    if verbose:\n",
    "        print (\"parcel_id {} start {} end {} crop {} len {}\".format(parcel_id, date_start.strftime(\"%d-%m-%Y\"), date_end.strftime(\"%d-%m-%Y\"), date_crop.strftime(\"%d-%m-%Y\"), len(df_filtered)))\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "def interval_from_the_begging_of_the_year_until_june(params_list, verbose=False):\n",
    "    parcel_id = params_list[0]\n",
    "    df_timeseries = params_list[1]\n",
    "    \n",
    "    date_crop = parcel_date_crop_dict[parcel_id]\n",
    "    date_end = datetime.datetime(date_crop.year, month=6, day=30)\n",
    "    date_start = datetime.datetime(date_crop.year, month=1, day=1)\n",
    "    \n",
    "    # temporal filter\n",
    "    df_filtered = df_timeseries[(df_timeseries.date >= date_start) & (df_timeseries.date <= date_end)]\n",
    "    \n",
    "    if verbose:\n",
    "        print (\"parcel_id {} start {} end {} crop {} len {}\".format(parcel_id, date_start.strftime(\"%d-%m-%Y\"), date_end.strftime(\"%d-%m-%Y\"), date_crop.strftime(\"%d-%m-%Y\"), len(df_filtered)))\n",
    "    \n",
    "    return df_filtered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ. How correlated are the satellite imagery indexes and the biologicy activity properties?\n",
    "\n",
    "The analytic API performs associations and correlations between the biologic activity properties and satellite imagery indexes (satellite data layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###  @parameters \n",
    "list_of_agg_value_columns = ['max', 'min', 'mean', 'std', 'count', 'sum']\n",
    "list_of_agg_time_functions = [interval_from_the_begging_of_the_year_until_march, \n",
    "                interval_from_the_begging_of_the_year_until_april, \n",
    "                interval_from_the_begging_of_the_year_until_may, \n",
    "                interval_from_the_begging_of_the_year_until_june]\n",
    "\n",
    "for agg_time_function in list_of_agg_time_functions:\n",
    "    plt.figure(figsize=(24,10))\n",
    "    idx_plot = 1\n",
    "    print(agg_time_function.__name__)\n",
    "    for agg_value_column in list_of_agg_value_columns:\n",
    "        correlation_matrix, x_labels, y_labels = fn_correlation_matrix(agg_value_column, agg_time_function, satellite_source, verbose=False)\n",
    "        # plot \n",
    "        plot_title = \"Agg.: {}. Intrv: {}\".format(agg_value_column, agg_time_function.__name__.replace(\"interval_\", \"\"))        \n",
    "        plot_heat_map(correlation_matrix, x_labels, y_labels, plot_title, (2,3), idx_plot)\n",
    "        idx_plot = idx_plot + 1\n",
    "        \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ. What are the most correlated satellite imagery indexes for each maceration property?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_agg_value_columns = ['max', 'min', 'mean', 'std', 'count', 'sum']\n",
    "list_of_agg_time_functions = [interval_from_the_begging_of_the_year_until_march, \n",
    "                interval_from_the_begging_of_the_year_until_april, \n",
    "                interval_from_the_begging_of_the_year_until_may, \n",
    "                interval_from_the_begging_of_the_year_until_june]\n",
    "\n",
    "df_highest_corr = None\n",
    "for agg_value_column in list_of_agg_value_columns:\n",
    "    for agg_time_function in list_of_agg_time_functions:\n",
    "        correlation_matrix, x_labels, y_labels = fn_correlation_matrix(agg_value_column, agg_time_function, satellite_source, verbose=False) # fn_correlation_matrix(agg_function, satellite_source, days_before_the_crop, verbose=False)\n",
    "        df_result = get_the_most_correlated_variables(correlation_matrix, x_labels, y_labels)\n",
    "        df_result['Agg_value_column'] = agg_value_column\n",
    "        df_result['Agg_time_function'] = agg_time_function.__name__\n",
    "        df_result['Source'] = satellite_source\n",
    "        \n",
    "        if df_highest_corr is None:\n",
    "            df_highest_corr = df_result\n",
    "        else:\n",
    "            df_highest_corr = pd.concat([df_highest_corr, df_result])\n",
    "\n",
    "                        \n",
    "pd.set_option('max_colwidth', 800)\n",
    "df_highest_corr_by_ba = df_highest_corr.sort_values(by=[type_analysis, 'Highest_Corr_Value_Abs'], ascending=False)\n",
    "df_highest_corr_by_ba = df_highest_corr_by_ba.drop_duplicates(subset=[type_analysis], keep='first')\n",
    "df_highest_corr_by_ba.rename(columns={'Product_Type':'Most_correlated_Product_Type'}, inplace=True)\n",
    "df_highest_corr_by_ba[[type_analysis, 'Most_correlated_Product_Type', 'Highest_Corr_Value', 'Highest_Corr_Value_Abs','Agg_time_function', 'Agg_value_column', 'Source']]\n",
    "df_highest_corr_by_ba = df_highest_corr_by_ba[[type_analysis, 'Most_correlated_Product_Type', 'Highest_Corr_Value', 'Highest_Corr_Value_Abs','Agg_time_function', 'Agg_value_column']]\n",
    "df_highest_corr_by_ba\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ. What are the most correlated maceration properties for each satellite imagery index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 800)\n",
    "\n",
    "df_highest_corr_by_Satellity_Index = df_highest_corr.sort_values(by=['Product_Type', 'Highest_Corr_Value_Abs'], ascending=False)\n",
    "df_highest_corr_by_Satellity_Index = df_highest_corr_by_Satellity_Index.drop_duplicates(subset=['Product_Type'], keep='first')\n",
    "df_highest_corr_by_Satellity_Index.rename(columns={type_analysis:'Most_correlated_{0}_Prop'.format(type_analysis)}, inplace=True)\n",
    "df_highest_corr_by_Satellity_Index[['Product_Type', 'Most_correlated_{0}_Prop'.format(type_analysis), 'Highest_Corr_Value', 'Highest_Corr_Value_Abs', 'Agg_time_function', 'Agg_value_column', 'Source']]\n",
    "\n",
    "\n",
    "df_highest_corr_by_Satellity_Index = df_highest_corr_by_Satellity_Index[['Product_Type', 'Most_correlated_{0}_Prop'.format(type_analysis), 'Highest_Corr_Value', 'Highest_Corr_Value_Abs', 'Agg_time_function', 'Agg_value_column']]\n",
    "df_highest_corr_by_Satellity_Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BDG-CorrelationAnalysis-Eleni.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
