{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/BDG_LOGO.png\" alt=\"drawing\" align=\"right\" width=\"200\"/>\n",
    "\n",
    "# H2020 RIA BigDataGrapes - Predictive Data Analytics (T4.3)\n",
    "\n",
    "### This deliverable (D4.3) presents how to train machine learning models with the BigDataGrapes distributed processing architecture. In particular, we present how to train classifiers with MLLib (https://spark.apache.org/mllib/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import urllib\n",
    "import random\n",
    "import numpy as np\n",
    "import pydoop.hdfs as hdfs\n",
    "\n",
    "from numpy import array\n",
    "from pyspark.mllib.regression import LabeledPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection to the BDG Apache Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standalone mode below\n",
    "#sc = SparkContext(appName=\"Classification-KDDCUP1999\", master=\"master[*]\")\n",
    "\n",
    "# distributed mode below\n",
    "sc = SparkContext(appName=\"Classification-KDDCUP1999\", master=\"spark://spark-master:7077\")\n",
    "\n",
    "# setting logger level\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification on a real dataset\n",
    "\n",
    "## We employ the KDD Cup 1999 dataset (http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html).\n",
    "\n",
    "### This is the data set used for The Third International Knowledge Discovery and Data Mining Tools Competition, which was held in conjunction with KDD-99 The Fifth International Conference on Knowledge Discovery and Data Mining. The competition task was to build a network intrusion detector, a predictive model capable of distinguishing between \"bad\" connections, called intrusions or attacks, and \"good\" normal connections. This database contains a standard set of data to be audited, which includes a wide variety of intrusions simulated in a military network environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the dataset from the Web and Reading it with Apache Spark (creating RDDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "path_on_disk = \"/tmp/kddcup.data.gz\"\n",
    "path_on_hdfs = \"hdfs://namenode:8020/user/root/kddcup11.data.gz\"\n",
    "urllib.urlretrieve(\"http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data.gz\", path_on_disk)\n",
    "hdfs.put(path_on_disk, path_on_hdfs)\n",
    "train_data = sc.textFile(path_on_hdfs)\n",
    "\n",
    "# # test data\n",
    "test_path_on_disk = \"/tmp/corrected.gz\"\n",
    "test_path_on_hdfs = \"hdfs://namenode:8020/user/root/corrected11.data.gz\"\n",
    "urllib.urlretrieve(\"http://kdd.ics.uci.edu/databases/kddcup99/corrected.gz\", test_path_on_disk)\n",
    "hdfs.put(test_path_on_disk, test_path_on_hdfs)\n",
    "test_data = sc.textFile(test_path_on_hdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing data to produce data with correct labels (1, 0).\n",
    "def parse_interaction(line):\n",
    "    line_split = line.split(\",\")\n",
    "    clean_line_split = line_split[0:1] + line_split[4:41]\n",
    "    attack = 1.0\n",
    "    if line_split[41]=='normal.':\n",
    "        attack = 0.0\n",
    "    return LabeledPoint(attack, array([float(x) for x in clean_line_split]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_train_data = train_data.map(parse_interaction)\n",
    "parsed_test_data = test_data.map(parse_interaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now training one Logistic Regression Classifier.\n",
    "\n",
    "### We also measure the time needed by MLLib to train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "\n",
    "%time logit_model = LogisticRegressionWithLBFGS.train(parsed_train_data, iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_and_preds = parsed_test_data.map(lambda p: (p.label, logit_model.predict(p.features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the performance of the classifier (Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 ms, sys: 20 ms, total: 28 ms\n",
      "Wall time: 17.2 s\n",
      "Accuracy on test data is 0.8052\n"
     ]
    }
   ],
   "source": [
    "%time test_accuracy = labels_and_preds.filter(lambda (v, p): v == p).count() / float(test_data.count())\n",
    "print \"Accuracy on test data is {}\".format(round(test_accuracy, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disconnection from the BDG Apache Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
