{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<img src=\"../images/BDG_LOGO.png\" alt=\"drawing\" align=\"right\" width=\"200\"/>\n",
    "\n",
    "# H2020 RIA BigDataGrapes - Predictive Data Analytics (T4.3)\n",
    "\n",
    "## Wine Making Pilot\n",
    "\n",
    "### This pilot is described in the deliverable D4.3 (Pilot 2).\n",
    "\n",
    "The specific goal of the price prediction is to develop a machine-learned pipeline aiming at counting leaves from side-view grapevine images taken into the imaging cabin of the PhenoArch platform (see picture below) managed by INRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.4)\n",
      "Requirement already satisfied: tqdm in /home/salvatore/.local/lib/python3.6/site-packages (4.42.0)\n",
      "Requirement already satisfied: keras_tqdm in /usr/local/lib/python3.6/dist-packages (2.0.1)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (0.16.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.15.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from keras) (3.12)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.23.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/lib/python3/dist-packages (from tensorflow) (0.30.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.1)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.6.1)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (6.2.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.2)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (3.2.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow) (47.1.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image) (4.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2018.1.18)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.6)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.22)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.1)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user pandas tqdm keras_tqdm keras tensorflow scikit-image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import json\n",
    "import traceback\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "\n",
    "import skimage\n",
    "from skimage import io, transform\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Dense, Input, Subtract, BatchNormalization, InputLayer\n",
    "from keras import backend as K, Model, regularizers, backend, optimizers\n",
    "from keras.constraints import maxnorm, Constraint\n",
    "from keras import initializers\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tqdm\n",
    "from keras_tqdm import TQDMNotebookCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pd.set_option('precision', 4)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "plt.rcParams['figure.facecolor'] = '#FFFFFF'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Set the dataset to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dataset = \"ARCH2012-03-14\"\n",
    "# dataset = \"ARCH2013-03-17\"\n",
    "\n",
    "json_file = f\"{dataset}_images_phenology_enriched.json\"\n",
    "\n",
    "if dataset == \"ARCH2012-03-14\":\n",
    "    path_dataset = f\"/data/{dataset}/\"\n",
    "elif dataset == \"ARCH2013-03-17\":\n",
    "    path_dataset = f\"/data/{dataset}/\"\n",
    "else:\n",
    "    print(\"Dataset not supported!!\")\n",
    "    path_dataset = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Load the dataset from json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Loading Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class ImageDataset(object):\n",
    "    \n",
    "    def __init__(self, image_list, labels, uris, plants, dates):\n",
    "        self.image_list = image_list\n",
    "        self.labels = labels\n",
    "        self.uris = uris\n",
    "        self.plants = plants\n",
    "        self.dates = dates\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.labels.size\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self)\n",
    "    \n",
    "    def num_plants(self):\n",
    "        return np.unique(self.plants).size\n",
    "    \n",
    "    def X_is_loaded(self):\n",
    "        return False\n",
    "    \n",
    "    def split(self, vali_ratio=0.2, test_ratio=0.2, shuffle=True, seed=42):\n",
    "        size = self.size()\n",
    "        indexes = np.arange(size)\n",
    "        if shuffle:\n",
    "            np.random.seed(seed)\n",
    "            indexes = np.random.permutation(indexes)\n",
    "        idx_start_vali = int(np.round(size * 0.6))\n",
    "        idx_start_test = int(np.round(size * 0.8))\n",
    "        \n",
    "        image_ids_train = indexes[:idx_start_vali]\n",
    "        image_ids_vali = indexes[idx_start_vali:idx_start_test]\n",
    "        image_ids_test = indexes[idx_start_test:]\n",
    "        \n",
    "        return (\n",
    "            ImageDataset(self.image_list[image_ids_train], self.labels[image_ids_train], self.uris[image_ids_train], self.plants[image_ids_train], self.dates[image_ids_train]), \n",
    "            ImageDataset(self.image_list[image_ids_vali],  self.labels[image_ids_vali],  self.uris[image_ids_vali],  self.plants[image_ids_vali], self.dates[image_ids_vali]),\n",
    "            ImageDataset(self.image_list[image_ids_test],  self.labels[image_ids_test],  self.uris[image_ids_test],  self.plants[image_ids_test], self.dates[image_ids_test])\n",
    "        )\n",
    "    \n",
    "    def split_by_plants(self, vali_ratio=0.2, test_ratio=0.2, shuffle=True, seed=42):\n",
    "        size = self.num_plants()\n",
    "        indexes = np.arange(size, dtype=np.uint16)\n",
    "        if shuffle:\n",
    "            np.random.seed(seed)\n",
    "            indexes = np.random.permutation(indexes)\n",
    "        idx_start_vali = int(np.round(size * 0.6))\n",
    "        idx_start_test = int(np.round(size * 0.8))\n",
    "        \n",
    "        plants_id_train = indexes[:idx_start_vali]\n",
    "        plants_id_vali  = indexes[idx_start_vali:idx_start_test]\n",
    "        plants_id_test  = indexes[idx_start_test:]\n",
    "        \n",
    "        idx_train = np.concatenate([np.arange(start, end) for start, end in zip(np.searchsorted(self.plants, plants_id_train, side='left'), np.searchsorted(self.plants, plants_id_train, side='right'))]).ravel()\n",
    "        idx_vali  = np.concatenate([np.arange(start, end) for start, end in zip(np.searchsorted(self.plants, plants_id_vali,  side='left'), np.searchsorted(self.plants, plants_id_vali,  side='right'))]).ravel()\n",
    "        idx_test  = np.concatenate([np.arange(start, end) for start, end in zip(np.searchsorted(self.plants, plants_id_test,  side='left'), np.searchsorted(self.plants, plants_id_test,  side='right'))]).ravel()\n",
    "        \n",
    "        return (\n",
    "            ImageDataset(self.image_list[idx_train], self.labels[idx_train], self.uris[idx_train], self.plants[idx_train], self.dates[idx_train]), \n",
    "            ImageDataset(self.image_list[idx_vali],  self.labels[idx_vali],  self.uris[idx_vali],  self.plants[idx_vali],  self.dates[idx_vali]),\n",
    "            ImageDataset(self.image_list[idx_test],  self.labels[idx_test],  self.uris[idx_test],  self.plants[idx_test],  self.dates[idx_test])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def read_annotated_json(json_file, path_dataset, skip_top=True):\n",
    "\n",
    "    labels = []\n",
    "    images = []\n",
    "    uris = []\n",
    "    plants = []\n",
    "    dates = []\n",
    "    with open(json_file, 'r') as reader:\n",
    "        for plant_num, line in enumerate(reader):\n",
    "            obj = json.loads(line)\n",
    "            for image in obj['images']:\n",
    "                if skip_top and 'top' in image['labelView']:\n",
    "                    continue\n",
    "                labels.append(obj['leafNumber'])\n",
    "                dates.append(obj['date'])\n",
    "                images.append(os.path.join(\n",
    "                    path_dataset, \n",
    "                    os.path.basename(image['filename'])\n",
    "                ))\n",
    "                uris.append(image['uri'])\n",
    "                plants.append(plant_num)\n",
    "                \n",
    "    return ImageDataset(\n",
    "        np.array(images, dtype=np.object), \n",
    "        np.array(labels, dtype=np.float32), \n",
    "        np.array(uris, dtype=object), \n",
    "        np.array(plants, dtype=np.uint16), \n",
    "        np.array(dates, dtype=object)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Read the dataset and split in Train, Vali and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 48810\n",
      "Vali Size: 16305\n",
      "Test Size: 16248\n"
     ]
    }
   ],
   "source": [
    "image_dataset = read_annotated_json(json_file, path_dataset, skip_top=False)\n",
    "train_dataset, vali_dataset, test_dataset = image_dataset.split_by_plants()\n",
    "\n",
    "print(\"Train Size: {}\\nVali Size: {}\\nTest Size: {}\".format(train_dataset.size(), vali_dataset.size(), test_dataset.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## NN Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed_value=0):\n",
    "\n",
    "    # 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "    # 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "    random.seed(seed_value)\n",
    "\n",
    "    # 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "    np.random.seed(seed_value)\n",
    "\n",
    "    # 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "    tf.set_random_seed(seed_value)\n",
    "\n",
    "    # 5. Configure a new global `tensorflow` session\n",
    "    session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class ImageGeneratorBatch(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, image_dataset, cropped_dim=(1800,800), rescale=0.25, n_channels=3, batch_size=32, shuffle=True, seed=42):\n",
    "        'Initialization'\n",
    "        self.cropped_dim = cropped_dim\n",
    "        self.rescale = rescale\n",
    "        self.final_dim = (int(self.cropped_dim[0]*self.rescale), int(self.cropped_dim[1]*self.rescale))\n",
    "        self.image_dataset = image_dataset\n",
    "        self.n_channels = n_channels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        np.random.seed(seed)\n",
    "        self.cur_idx = 0\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.ceil(self.image_dataset.size() / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        if index == (len(self)-1):\n",
    "            indexes = self.indexes[index*self.batch_size:]\n",
    "\n",
    "        # Find list of URIs\n",
    "        list_images_batch = self.image_dataset.image_list[indexes]\n",
    "\n",
    "        # Generate data\n",
    "        if self.image_dataset.X_is_loaded():\n",
    "            X = self.image_dataset.X[indexes]\n",
    "        else:\n",
    "            X = self.__data_generation(list_images_batch)\n",
    "\n",
    "        y = self.image_dataset.labels[indexes]\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(self.image_dataset.size())\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_images_batch):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        new_h, new_w = self.cropped_dim[0], self.cropped_dim[1]\n",
    "        \n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.final_dim, self.n_channels))\n",
    "\n",
    "        # Generate data\n",
    "        for i, image_path in enumerate(list_images_batch):\n",
    "            \n",
    "            try:\n",
    "                img = skimage.io.imread(image_path)\n",
    "                if self.n_channels == 3:\n",
    "                    # remove alpha channel\n",
    "                    img = img[:,:,:3]\n",
    "    \n",
    "                cropped_img = skimage.util.crop(img, (\n",
    "                                                   (20, img.shape[0] - new_h - 20), \n",
    "                                                   (int( (img.shape[1] - new_w) / 2), int( (img.shape[1] - new_w) / 2)), \n",
    "                                                   (0,0)\n",
    "                                               ),\n",
    "                                               copy=False)\n",
    "        \n",
    "                X[i,] = skimage.img_as_ubyte(skimage.transform.rescale(cropped_img, self.rescale, anti_aliasing=True, preserve_range=False, multichannel=True), force_copy=False)\n",
    "            except:\n",
    "                print(\"Unexpected error on index {} for image {}: {}\".format(self.cur_idx, list_images_batch[i], traceback.format_exc()))\n",
    "                X[i,] = np.zeros((*self.final_dim, self.n_channels), dtype=np.uint8)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def create_model(conv_layers, dense_layers, height, width, channels):\n",
    "    \n",
    "    def ConvBlock(n_conv, filters, kernel_size, strides=(1,1), padding='same', kernel_initializer='he_uniform', activation='relu', is_last=False, bnorm=False, dropout=0.0):\n",
    "\n",
    "        for i in range(n_conv):\n",
    "            model.add(keras.layers.Conv2D(filters, kernel_size, strides=strides, padding=padding, kernel_initializer=kernel_initializer))\n",
    "            if bnorm:\n",
    "                model.add(keras.layers.BatchNormalization())\n",
    "            model.add(keras.layers.Activation(activation))\n",
    "\n",
    "        if is_last:\n",
    "            model.add(keras.layers.GlobalMaxPooling2D())\n",
    "        else:\n",
    "            model.add(keras.layers.MaxPooling2D())\n",
    "        \"\"\n",
    "        if dropout > 0:\n",
    "            model.add(keras.layers.Dropout(dropout))\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def DenseBlock(size, kernel_initializer='glorot_uniform', activation='relu', is_last=False, bnorm=False, dropout=0.0, bias_initializer=0):\n",
    "\n",
    "        model.add(keras.layers.Dense(size, kernel_initializer=kernel_initializer, bias_initializer=keras.initializers.Constant(value=bias_initializer)))\n",
    "\n",
    "        if not is_last:\n",
    "            if bnorm:\n",
    "                model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "            model.add(keras.layers.Activation(activation))\n",
    "\n",
    "            if dropout > 0:\n",
    "                model.add(keras.layers.Dropout(dropout))\n",
    "\n",
    "        return\n",
    "\n",
    "    # reset seed of keras\n",
    "    tf.random.set_seed(0)\n",
    "\n",
    "    model = keras.models.Sequential(name='Leaf Counter')\n",
    "    \n",
    "    model.add(\n",
    "        keras.layers.InputLayer(\n",
    "            input_shape=(height, width, channels),\n",
    "            name='input'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    for i, params in enumerate(conv_layers):\n",
    "        is_last = i == len(conv_layers)-1\n",
    "        ConvBlock(is_last=is_last, **params)\n",
    "\n",
    "    for i, params in enumerate(dense_layers):\n",
    "        is_last = i == len(dense_layers)-1\n",
    "        DenseBlock(is_last=is_last, **params)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='mae', \n",
    "                  optimizer=keras.optimizers.Adadelta(),# Adam(),\n",
    "                  metrics=[keras.metrics.mae, keras.metrics.mse])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def describe_model(model): \n",
    "\n",
    "    pd.set_option('max_colwidth', -1)\n",
    "    pd.set_option('display.max_rows', 999)\n",
    "    layers = [(layer.__class__.__name__, layer.name, layer.input_shape, layer.output_shape, layer.count_params(), layer.trainable) for layer in model.layers]\n",
    "    df = pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Input Shape', 'Output Shape', \"# Params\", 'Trainable'])\n",
    "    display.display(df)\n",
    "\n",
    "    print(\"Total params: {:,}\".format(df['# Params'].sum()))\n",
    "    print(\"Non-trainable params: {:,}\".format(df[df['Trainable'] == False]['# Params'].sum()))\n",
    "    print(\"Trainable params: {:,}\".format(df[df['Trainable'] == True]['# Params'].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Create the Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Type</th>\n",
       "      <th>Layer Name</th>\n",
       "      <th>Input Shape</th>\n",
       "      <th>Output Shape</th>\n",
       "      <th># Params</th>\n",
       "      <th>Trainable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Conv2D</td>\n",
       "      <td>conv2d_17</td>\n",
       "      <td>(None, 450, 200, 3)</td>\n",
       "      <td>(None, 450, 200, 4)</td>\n",
       "      <td>112</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BatchNormalization</td>\n",
       "      <td>batch_normalization_20</td>\n",
       "      <td>(None, 450, 200, 4)</td>\n",
       "      <td>(None, 450, 200, 4)</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Activation</td>\n",
       "      <td>activation_20</td>\n",
       "      <td>(None, 450, 200, 4)</td>\n",
       "      <td>(None, 450, 200, 4)</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conv2D</td>\n",
       "      <td>conv2d_18</td>\n",
       "      <td>(None, 450, 200, 4)</td>\n",
       "      <td>(None, 450, 200, 4)</td>\n",
       "      <td>148</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BatchNormalization</td>\n",
       "      <td>batch_normalization_21</td>\n",
       "      <td>(None, 450, 200, 4)</td>\n",
       "      <td>(None, 450, 200, 4)</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Activation</td>\n",
       "      <td>activation_21</td>\n",
       "      <td>(None, 450, 200, 4)</td>\n",
       "      <td>(None, 450, 200, 4)</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MaxPooling2D</td>\n",
       "      <td>max_pooling2d_8</td>\n",
       "      <td>(None, 450, 200, 4)</td>\n",
       "      <td>(None, 225, 100, 4)</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conv2D</td>\n",
       "      <td>conv2d_19</td>\n",
       "      <td>(None, 225, 100, 4)</td>\n",
       "      <td>(None, 225, 100, 8)</td>\n",
       "      <td>296</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BatchNormalization</td>\n",
       "      <td>batch_normalization_22</td>\n",
       "      <td>(None, 225, 100, 8)</td>\n",
       "      <td>(None, 225, 100, 8)</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Activation</td>\n",
       "      <td>activation_22</td>\n",
       "      <td>(None, 225, 100, 8)</td>\n",
       "      <td>(None, 225, 100, 8)</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Conv2D</td>\n",
       "      <td>conv2d_20</td>\n",
       "      <td>(None, 225, 100, 8)</td>\n",
       "      <td>(None, 225, 100, 8)</td>\n",
       "      <td>584</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BatchNormalization</td>\n",
       "      <td>batch_normalization_23</td>\n",
       "      <td>(None, 225, 100, 8)</td>\n",
       "      <td>(None, 225, 100, 8)</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Activation</td>\n",
       "      <td>activation_23</td>\n",
       "      <td>(None, 225, 100, 8)</td>\n",
       "      <td>(None, 225, 100, 8)</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MaxPooling2D</td>\n",
       "      <td>max_pooling2d_9</td>\n",
       "      <td>(None, 225, 100, 8)</td>\n",
       "      <td>(None, 112, 50, 8)</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Conv2D</td>\n",
       "      <td>conv2d_21</td>\n",
       "      <td>(None, 112, 50, 8)</td>\n",
       "      <td>(None, 112, 50, 16)</td>\n",
       "      <td>1168</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BatchNormalization</td>\n",
       "      <td>batch_normalization_24</td>\n",
       "      <td>(None, 112, 50, 16)</td>\n",
       "      <td>(None, 112, 50, 16)</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Activation</td>\n",
       "      <td>activation_24</td>\n",
       "      <td>(None, 112, 50, 16)</td>\n",
       "      <td>(None, 112, 50, 16)</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Conv2D</td>\n",
       "      <td>conv2d_22</td>\n",
       "      <td>(None, 112, 50, 16)</td>\n",
       "      <td>(None, 112, 50, 16)</td>\n",
       "      <td>2320</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BatchNormalization</td>\n",
       "      <td>batch_normalization_25</td>\n",
       "      <td>(None, 112, 50, 16)</td>\n",
       "      <td>(None, 112, 50, 16)</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Activation</td>\n",
       "      <td>activation_25</td>\n",
       "      <td>(None, 112, 50, 16)</td>\n",
       "      <td>(None, 112, 50, 16)</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MaxPooling2D</td>\n",
       "      <td>max_pooling2d_10</td>\n",
       "      <td>(None, 112, 50, 16)</td>\n",
       "      <td>(None, 56, 25, 16)</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Conv2D</td>\n",
       "      <td>conv2d_23</td>\n",
       "      <td>(None, 56, 25, 16)</td>\n",
       "      <td>(None, 56, 25, 32)</td>\n",
       "      <td>4640</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BatchNormalization</td>\n",
       "      <td>batch_normalization_26</td>\n",
       "      <td>(None, 56, 25, 32)</td>\n",
       "      <td>(None, 56, 25, 32)</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Activation</td>\n",
       "      <td>activation_26</td>\n",
       "      <td>(None, 56, 25, 32)</td>\n",
       "      <td>(None, 56, 25, 32)</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Conv2D</td>\n",
       "      <td>conv2d_24</td>\n",
       "      <td>(None, 56, 25, 32)</td>\n",
       "      <td>(None, 56, 25, 32)</td>\n",
       "      <td>9248</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BatchNormalization</td>\n",
       "      <td>batch_normalization_27</td>\n",
       "      <td>(None, 56, 25, 32)</td>\n",
       "      <td>(None, 56, 25, 32)</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Activation</td>\n",
       "      <td>activation_27</td>\n",
       "      <td>(None, 56, 25, 32)</td>\n",
       "      <td>(None, 56, 25, 32)</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MaxPooling2D</td>\n",
       "      <td>max_pooling2d_11</td>\n",
       "      <td>(None, 56, 25, 32)</td>\n",
       "      <td>(None, 28, 12, 32)</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Conv2D</td>\n",
       "      <td>conv2d_25</td>\n",
       "      <td>(None, 28, 12, 32)</td>\n",
       "      <td>(None, 28, 12, 64)</td>\n",
       "      <td>18496</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BatchNormalization</td>\n",
       "      <td>batch_normalization_28</td>\n",
       "      <td>(None, 28, 12, 64)</td>\n",
       "      <td>(None, 28, 12, 64)</td>\n",
       "      <td>256</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Activation</td>\n",
       "      <td>activation_28</td>\n",
       "      <td>(None, 28, 12, 64)</td>\n",
       "      <td>(None, 28, 12, 64)</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Conv2D</td>\n",
       "      <td>conv2d_26</td>\n",
       "      <td>(None, 28, 12, 64)</td>\n",
       "      <td>(None, 28, 12, 64)</td>\n",
       "      <td>36928</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BatchNormalization</td>\n",
       "      <td>batch_normalization_29</td>\n",
       "      <td>(None, 28, 12, 64)</td>\n",
       "      <td>(None, 28, 12, 64)</td>\n",
       "      <td>256</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Activation</td>\n",
       "      <td>activation_29</td>\n",
       "      <td>(None, 28, 12, 64)</td>\n",
       "      <td>(None, 28, 12, 64)</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>MaxPooling2D</td>\n",
       "      <td>max_pooling2d_12</td>\n",
       "      <td>(None, 28, 12, 64)</td>\n",
       "      <td>(None, 14, 6, 64)</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Conv2D</td>\n",
       "      <td>conv2d_27</td>\n",
       "      <td>(None, 14, 6, 64)</td>\n",
       "      <td>(None, 14, 6, 128)</td>\n",
       "      <td>73856</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>BatchNormalization</td>\n",
       "      <td>batch_normalization_30</td>\n",
       "      <td>(None, 14, 6, 128)</td>\n",
       "      <td>(None, 14, 6, 128)</td>\n",
       "      <td>512</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Activation</td>\n",
       "      <td>activation_30</td>\n",
       "      <td>(None, 14, 6, 128)</td>\n",
       "      <td>(None, 14, 6, 128)</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Conv2D</td>\n",
       "      <td>conv2d_28</td>\n",
       "      <td>(None, 14, 6, 128)</td>\n",
       "      <td>(None, 14, 6, 128)</td>\n",
       "      <td>147584</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>BatchNormalization</td>\n",
       "      <td>batch_normalization_31</td>\n",
       "      <td>(None, 14, 6, 128)</td>\n",
       "      <td>(None, 14, 6, 128)</td>\n",
       "      <td>512</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Activation</td>\n",
       "      <td>activation_31</td>\n",
       "      <td>(None, 14, 6, 128)</td>\n",
       "      <td>(None, 14, 6, 128)</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>MaxPooling2D</td>\n",
       "      <td>max_pooling2d_13</td>\n",
       "      <td>(None, 14, 6, 128)</td>\n",
       "      <td>(None, 7, 3, 128)</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Conv2D</td>\n",
       "      <td>conv2d_29</td>\n",
       "      <td>(None, 7, 3, 128)</td>\n",
       "      <td>(None, 7, 3, 256)</td>\n",
       "      <td>295168</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>BatchNormalization</td>\n",
       "      <td>batch_normalization_32</td>\n",
       "      <td>(None, 7, 3, 256)</td>\n",
       "      <td>(None, 7, 3, 256)</td>\n",
       "      <td>1024</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Activation</td>\n",
       "      <td>activation_32</td>\n",
       "      <td>(None, 7, 3, 256)</td>\n",
       "      <td>(None, 7, 3, 256)</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Conv2D</td>\n",
       "      <td>conv2d_30</td>\n",
       "      <td>(None, 7, 3, 256)</td>\n",
       "      <td>(None, 7, 3, 256)</td>\n",
       "      <td>590080</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>BatchNormalization</td>\n",
       "      <td>batch_normalization_33</td>\n",
       "      <td>(None, 7, 3, 256)</td>\n",
       "      <td>(None, 7, 3, 256)</td>\n",
       "      <td>1024</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Activation</td>\n",
       "      <td>activation_33</td>\n",
       "      <td>(None, 7, 3, 256)</td>\n",
       "      <td>(None, 7, 3, 256)</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>MaxPooling2D</td>\n",
       "      <td>max_pooling2d_14</td>\n",
       "      <td>(None, 7, 3, 256)</td>\n",
       "      <td>(None, 3, 1, 256)</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Conv2D</td>\n",
       "      <td>conv2d_31</td>\n",
       "      <td>(None, 3, 1, 256)</td>\n",
       "      <td>(None, 3, 1, 512)</td>\n",
       "      <td>1180160</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>BatchNormalization</td>\n",
       "      <td>batch_normalization_34</td>\n",
       "      <td>(None, 3, 1, 512)</td>\n",
       "      <td>(None, 3, 1, 512)</td>\n",
       "      <td>2048</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Activation</td>\n",
       "      <td>activation_34</td>\n",
       "      <td>(None, 3, 1, 512)</td>\n",
       "      <td>(None, 3, 1, 512)</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Conv2D</td>\n",
       "      <td>conv2d_32</td>\n",
       "      <td>(None, 3, 1, 512)</td>\n",
       "      <td>(None, 3, 1, 512)</td>\n",
       "      <td>2359808</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>BatchNormalization</td>\n",
       "      <td>batch_normalization_35</td>\n",
       "      <td>(None, 3, 1, 512)</td>\n",
       "      <td>(None, 3, 1, 512)</td>\n",
       "      <td>2048</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Activation</td>\n",
       "      <td>activation_35</td>\n",
       "      <td>(None, 3, 1, 512)</td>\n",
       "      <td>(None, 3, 1, 512)</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>GlobalMaxPooling2D</td>\n",
       "      <td>global_max_pooling2d_2</td>\n",
       "      <td>(None, 3, 1, 512)</td>\n",
       "      <td>(None, 512)</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Dense</td>\n",
       "      <td>dense_5</td>\n",
       "      <td>(None, 512)</td>\n",
       "      <td>(None, 1024)</td>\n",
       "      <td>525312</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>BatchNormalization</td>\n",
       "      <td>batch_normalization_36</td>\n",
       "      <td>(None, 1024)</td>\n",
       "      <td>(None, 1024)</td>\n",
       "      <td>4096</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Activation</td>\n",
       "      <td>activation_36</td>\n",
       "      <td>(None, 1024)</td>\n",
       "      <td>(None, 1024)</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Dense</td>\n",
       "      <td>dense_6</td>\n",
       "      <td>(None, 1024)</td>\n",
       "      <td>(None, 1024)</td>\n",
       "      <td>1049600</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>BatchNormalization</td>\n",
       "      <td>batch_normalization_37</td>\n",
       "      <td>(None, 1024)</td>\n",
       "      <td>(None, 1024)</td>\n",
       "      <td>4096</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Activation</td>\n",
       "      <td>activation_37</td>\n",
       "      <td>(None, 1024)</td>\n",
       "      <td>(None, 1024)</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Dense</td>\n",
       "      <td>dense_7</td>\n",
       "      <td>(None, 1024)</td>\n",
       "      <td>(None, 1024)</td>\n",
       "      <td>1049600</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>BatchNormalization</td>\n",
       "      <td>batch_normalization_38</td>\n",
       "      <td>(None, 1024)</td>\n",
       "      <td>(None, 1024)</td>\n",
       "      <td>4096</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Activation</td>\n",
       "      <td>activation_38</td>\n",
       "      <td>(None, 1024)</td>\n",
       "      <td>(None, 1024)</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Dense</td>\n",
       "      <td>dense_8</td>\n",
       "      <td>(None, 1024)</td>\n",
       "      <td>(None, 1)</td>\n",
       "      <td>1025</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Layer Type              Layer Name          Input Shape  \\\n",
       "0   Conv2D              conv2d_17               (None, 450, 200, 3)   \n",
       "1   BatchNormalization  batch_normalization_20  (None, 450, 200, 4)   \n",
       "2   Activation          activation_20           (None, 450, 200, 4)   \n",
       "3   Conv2D              conv2d_18               (None, 450, 200, 4)   \n",
       "4   BatchNormalization  batch_normalization_21  (None, 450, 200, 4)   \n",
       "5   Activation          activation_21           (None, 450, 200, 4)   \n",
       "6   MaxPooling2D        max_pooling2d_8         (None, 450, 200, 4)   \n",
       "7   Conv2D              conv2d_19               (None, 225, 100, 4)   \n",
       "8   BatchNormalization  batch_normalization_22  (None, 225, 100, 8)   \n",
       "9   Activation          activation_22           (None, 225, 100, 8)   \n",
       "10  Conv2D              conv2d_20               (None, 225, 100, 8)   \n",
       "11  BatchNormalization  batch_normalization_23  (None, 225, 100, 8)   \n",
       "12  Activation          activation_23           (None, 225, 100, 8)   \n",
       "13  MaxPooling2D        max_pooling2d_9         (None, 225, 100, 8)   \n",
       "14  Conv2D              conv2d_21               (None, 112, 50, 8)    \n",
       "15  BatchNormalization  batch_normalization_24  (None, 112, 50, 16)   \n",
       "16  Activation          activation_24           (None, 112, 50, 16)   \n",
       "17  Conv2D              conv2d_22               (None, 112, 50, 16)   \n",
       "18  BatchNormalization  batch_normalization_25  (None, 112, 50, 16)   \n",
       "19  Activation          activation_25           (None, 112, 50, 16)   \n",
       "20  MaxPooling2D        max_pooling2d_10        (None, 112, 50, 16)   \n",
       "21  Conv2D              conv2d_23               (None, 56, 25, 16)    \n",
       "22  BatchNormalization  batch_normalization_26  (None, 56, 25, 32)    \n",
       "23  Activation          activation_26           (None, 56, 25, 32)    \n",
       "24  Conv2D              conv2d_24               (None, 56, 25, 32)    \n",
       "25  BatchNormalization  batch_normalization_27  (None, 56, 25, 32)    \n",
       "26  Activation          activation_27           (None, 56, 25, 32)    \n",
       "27  MaxPooling2D        max_pooling2d_11        (None, 56, 25, 32)    \n",
       "28  Conv2D              conv2d_25               (None, 28, 12, 32)    \n",
       "29  BatchNormalization  batch_normalization_28  (None, 28, 12, 64)    \n",
       "30  Activation          activation_28           (None, 28, 12, 64)    \n",
       "31  Conv2D              conv2d_26               (None, 28, 12, 64)    \n",
       "32  BatchNormalization  batch_normalization_29  (None, 28, 12, 64)    \n",
       "33  Activation          activation_29           (None, 28, 12, 64)    \n",
       "34  MaxPooling2D        max_pooling2d_12        (None, 28, 12, 64)    \n",
       "35  Conv2D              conv2d_27               (None, 14, 6, 64)     \n",
       "36  BatchNormalization  batch_normalization_30  (None, 14, 6, 128)    \n",
       "37  Activation          activation_30           (None, 14, 6, 128)    \n",
       "38  Conv2D              conv2d_28               (None, 14, 6, 128)    \n",
       "39  BatchNormalization  batch_normalization_31  (None, 14, 6, 128)    \n",
       "40  Activation          activation_31           (None, 14, 6, 128)    \n",
       "41  MaxPooling2D        max_pooling2d_13        (None, 14, 6, 128)    \n",
       "42  Conv2D              conv2d_29               (None, 7, 3, 128)     \n",
       "43  BatchNormalization  batch_normalization_32  (None, 7, 3, 256)     \n",
       "44  Activation          activation_32           (None, 7, 3, 256)     \n",
       "45  Conv2D              conv2d_30               (None, 7, 3, 256)     \n",
       "46  BatchNormalization  batch_normalization_33  (None, 7, 3, 256)     \n",
       "47  Activation          activation_33           (None, 7, 3, 256)     \n",
       "48  MaxPooling2D        max_pooling2d_14        (None, 7, 3, 256)     \n",
       "49  Conv2D              conv2d_31               (None, 3, 1, 256)     \n",
       "50  BatchNormalization  batch_normalization_34  (None, 3, 1, 512)     \n",
       "51  Activation          activation_34           (None, 3, 1, 512)     \n",
       "52  Conv2D              conv2d_32               (None, 3, 1, 512)     \n",
       "53  BatchNormalization  batch_normalization_35  (None, 3, 1, 512)     \n",
       "54  Activation          activation_35           (None, 3, 1, 512)     \n",
       "55  GlobalMaxPooling2D  global_max_pooling2d_2  (None, 3, 1, 512)     \n",
       "56  Dense               dense_5                 (None, 512)           \n",
       "57  BatchNormalization  batch_normalization_36  (None, 1024)          \n",
       "58  Activation          activation_36           (None, 1024)          \n",
       "59  Dense               dense_6                 (None, 1024)          \n",
       "60  BatchNormalization  batch_normalization_37  (None, 1024)          \n",
       "61  Activation          activation_37           (None, 1024)          \n",
       "62  Dense               dense_7                 (None, 1024)          \n",
       "63  BatchNormalization  batch_normalization_38  (None, 1024)          \n",
       "64  Activation          activation_38           (None, 1024)          \n",
       "65  Dense               dense_8                 (None, 1024)          \n",
       "\n",
       "           Output Shape  # Params  Trainable  \n",
       "0   (None, 450, 200, 4)  112       True       \n",
       "1   (None, 450, 200, 4)  16        True       \n",
       "2   (None, 450, 200, 4)  0         True       \n",
       "3   (None, 450, 200, 4)  148       True       \n",
       "4   (None, 450, 200, 4)  16        True       \n",
       "5   (None, 450, 200, 4)  0         True       \n",
       "6   (None, 225, 100, 4)  0         True       \n",
       "7   (None, 225, 100, 8)  296       True       \n",
       "8   (None, 225, 100, 8)  32        True       \n",
       "9   (None, 225, 100, 8)  0         True       \n",
       "10  (None, 225, 100, 8)  584       True       \n",
       "11  (None, 225, 100, 8)  32        True       \n",
       "12  (None, 225, 100, 8)  0         True       \n",
       "13  (None, 112, 50, 8)   0         True       \n",
       "14  (None, 112, 50, 16)  1168      True       \n",
       "15  (None, 112, 50, 16)  64        True       \n",
       "16  (None, 112, 50, 16)  0         True       \n",
       "17  (None, 112, 50, 16)  2320      True       \n",
       "18  (None, 112, 50, 16)  64        True       \n",
       "19  (None, 112, 50, 16)  0         True       \n",
       "20  (None, 56, 25, 16)   0         True       \n",
       "21  (None, 56, 25, 32)   4640      True       \n",
       "22  (None, 56, 25, 32)   128       True       \n",
       "23  (None, 56, 25, 32)   0         True       \n",
       "24  (None, 56, 25, 32)   9248      True       \n",
       "25  (None, 56, 25, 32)   128       True       \n",
       "26  (None, 56, 25, 32)   0         True       \n",
       "27  (None, 28, 12, 32)   0         True       \n",
       "28  (None, 28, 12, 64)   18496     True       \n",
       "29  (None, 28, 12, 64)   256       True       \n",
       "30  (None, 28, 12, 64)   0         True       \n",
       "31  (None, 28, 12, 64)   36928     True       \n",
       "32  (None, 28, 12, 64)   256       True       \n",
       "33  (None, 28, 12, 64)   0         True       \n",
       "34  (None, 14, 6, 64)    0         True       \n",
       "35  (None, 14, 6, 128)   73856     True       \n",
       "36  (None, 14, 6, 128)   512       True       \n",
       "37  (None, 14, 6, 128)   0         True       \n",
       "38  (None, 14, 6, 128)   147584    True       \n",
       "39  (None, 14, 6, 128)   512       True       \n",
       "40  (None, 14, 6, 128)   0         True       \n",
       "41  (None, 7, 3, 128)    0         True       \n",
       "42  (None, 7, 3, 256)    295168    True       \n",
       "43  (None, 7, 3, 256)    1024      True       \n",
       "44  (None, 7, 3, 256)    0         True       \n",
       "45  (None, 7, 3, 256)    590080    True       \n",
       "46  (None, 7, 3, 256)    1024      True       \n",
       "47  (None, 7, 3, 256)    0         True       \n",
       "48  (None, 3, 1, 256)    0         True       \n",
       "49  (None, 3, 1, 512)    1180160   True       \n",
       "50  (None, 3, 1, 512)    2048      True       \n",
       "51  (None, 3, 1, 512)    0         True       \n",
       "52  (None, 3, 1, 512)    2359808   True       \n",
       "53  (None, 3, 1, 512)    2048      True       \n",
       "54  (None, 3, 1, 512)    0         True       \n",
       "55  (None, 512)          0         True       \n",
       "56  (None, 1024)         525312    True       \n",
       "57  (None, 1024)         4096      True       \n",
       "58  (None, 1024)         0         True       \n",
       "59  (None, 1024)         1049600   True       \n",
       "60  (None, 1024)         4096      True       \n",
       "61  (None, 1024)         0         True       \n",
       "62  (None, 1024)         1049600   True       \n",
       "63  (None, 1024)         4096      True       \n",
       "64  (None, 1024)         0         True       \n",
       "65  (None, 1)            1025      True       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 7,366,581\n",
      "Non-trainable params: 0\n",
      "Trainable params: 7,366,581\n"
     ]
    }
   ],
   "source": [
    "WIDTH_IMAGES = 200\n",
    "HEIGHT_IMAGES = 450\n",
    "CHANNELS = 3\n",
    "\n",
    "model = create_model(\n",
    "    conv_layers=[\n",
    "            {'n_conv':2, 'filters':4,   'kernel_size':(3,3), 'strides':(1, 1), 'bnorm':True, 'activation':'relu'},\n",
    "            {'n_conv':2, 'filters':8,   'kernel_size':(3,3), 'strides':(1, 1), 'bnorm':True, 'activation':'relu'},\n",
    "            {'n_conv':2, 'filters':16,  'kernel_size':(3,3), 'strides':(1, 1), 'bnorm':True, 'activation':'relu'},\n",
    "            {'n_conv':2, 'filters':32,  'kernel_size':(3,3), 'strides':(1, 1), 'bnorm':True, 'activation':'relu'},\n",
    "            {'n_conv':2, 'filters':64,  'kernel_size':(3,3), 'strides':(1, 1), 'bnorm':True, 'activation':'relu'},\n",
    "            {'n_conv':2, 'filters':128, 'kernel_size':(3,3), 'strides':(1, 1), 'bnorm':True, 'activation':'relu'},\n",
    "            {'n_conv':2, 'filters':256, 'kernel_size':(3,3), 'strides':(1, 1), 'bnorm':True, 'activation':'relu'},\n",
    "            {'n_conv':2, 'filters':512, 'kernel_size':(3,3), 'strides':(1, 1), 'bnorm':True, 'activation':'relu'},\n",
    "        ],\n",
    "    dense_layers=[\n",
    "        {'size':1024, 'bnorm':True,  'activation':'relu'},\n",
    "        {'size':1024, 'bnorm':True,  'activation':'relu'},\n",
    "        {'size':1024, 'bnorm':True,  'activation':'relu'},\n",
    "        {'size':1,    'bnorm':False},\n",
    "    ],\n",
    "    width=WIDTH_IMAGES, height=HEIGHT_IMAGES, channels=CHANNELS,\n",
    ")\n",
    "\n",
    "print ('Model Summary')\n",
    "describe_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Train the Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=16\n",
    "nb_epoch=500\n",
    "\n",
    "CROPPED_WIDTH_IMAGES = 800\n",
    "CROPPED_HEIGHT_IMAGES = 1800\n",
    "RESCALE = 0.25\n",
    "CHANNELS = 3\n",
    "\n",
    "train_generator = ImageGeneratorBatch(train_dataset, cropped_dim=(CROPPED_HEIGHT_IMAGES, CROPPED_WIDTH_IMAGES), rescale=RESCALE, n_channels=CHANNELS, batch_size=BATCH_SIZE, shuffle=True, seed=42)\n",
    "vali_generator  = ImageGeneratorBatch(vali_dataset,  cropped_dim=(CROPPED_HEIGHT_IMAGES, CROPPED_WIDTH_IMAGES), rescale=RESCALE, n_channels=CHANNELS, batch_size=BATCH_SIZE, shuffle=True, seed=42)\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_mean_absolute_error',\n",
    "                                               min_delta=0,\n",
    "                                               patience=50,\n",
    "                                               verbose=0, \n",
    "                                               mode='auto',\n",
    "                                               restore_best_weights=True)\n",
    "\n",
    "progress_bar = TQDMNotebookCallback(\n",
    "    leave_inner=True, \n",
    "    leave_outer=True,\n",
    "    metric_format=\"{name}: {value:0.4f}\"\n",
    ")\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=nb_epoch, \n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping], #, progress_bar\n",
    "    validation_data=vali_generator, \n",
    "    validation_steps=len(vali_generator),\n",
    "    max_queue_size=10,\n",
    "    workers=1, \n",
    "    use_multiprocessing=False, \n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Save the model on file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model.save_weights(f\"{dataset}/plant_splitting_big_model_0.87_valid.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Load the model from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "WIDTH_IMAGES = 200\n",
    "HEIGHT_IMAGES = 450\n",
    "CHANNELS = 3\n",
    "\n",
    "model = create_model(\n",
    "    conv_layers=[\n",
    "            {'n_conv':2, 'filters':4,   'kernel_size':(3,3), 'strides':(1, 1), 'bnorm':True, 'activation':'relu'},\n",
    "            {'n_conv':2, 'filters':8,   'kernel_size':(3,3), 'strides':(1, 1), 'bnorm':True, 'activation':'relu'},\n",
    "            {'n_conv':2, 'filters':16,  'kernel_size':(3,3), 'strides':(1, 1), 'bnorm':True, 'activation':'relu'},\n",
    "            {'n_conv':2, 'filters':32,  'kernel_size':(3,3), 'strides':(1, 1), 'bnorm':True, 'activation':'relu'},\n",
    "            {'n_conv':2, 'filters':64,  'kernel_size':(3,3), 'strides':(1, 1), 'bnorm':True, 'activation':'relu'},\n",
    "            {'n_conv':2, 'filters':128, 'kernel_size':(3,3), 'strides':(1, 1), 'bnorm':True, 'activation':'relu'},\n",
    "            {'n_conv':2, 'filters':256, 'kernel_size':(3,3), 'strides':(1, 1), 'bnorm':True, 'activation':'relu'},\n",
    "            {'n_conv':2, 'filters':512, 'kernel_size':(3,3), 'strides':(1, 1), 'bnorm':True, 'activation':'relu'},\n",
    "        ],\n",
    "    dense_layers=[\n",
    "        {'size':1024, 'bnorm':True,  'activation':'relu'},\n",
    "        {'size':1024, 'bnorm':True,  'activation':'relu'},\n",
    "        {'size':1024, 'bnorm':True,  'activation':'relu'},\n",
    "        {'size':1,    'bnorm':False},\n",
    "    ],\n",
    "    width=WIDTH_IMAGES, height=HEIGHT_IMAGES, channels=CHANNELS,\n",
    ")\n",
    "\n",
    "model.load_weights(\"./plant_splitting_big_model_0.87_valid.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Compute the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "preds = {}\n",
    "datasets = [train_dataset, vali_dataset, test_dataset]\n",
    "\n",
    "for dataset in datasets:\n",
    "    dataset_generator = ImageGeneratorBatch(dataset, cropped_dim=(CROPPED_HEIGHT_IMAGES, CROPPED_WIDTH_IMAGES), rescale=RESCALE, n_channels=CHANNELS, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    preds[dataset] = model.predict_generator(dataset_generator, max_queue_size=1, workers=1, use_multiprocessing=False).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Compute the Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE: 0.2940\n",
      "Vali  MAE: 0.8674\n",
      "Test  MAE: 0.8776\n"
     ]
    }
   ],
   "source": [
    "mae = []\n",
    "for dataset in datasets:\n",
    "    mae.append(np.abs(dataset.labels - preds[dataset]).mean())\n",
    "\n",
    "print(f\"Train MAE: {mae[0]:.4f}\\nVali  MAE: {mae[1]:.4f}\\nTest  MAE: {mae[2]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
