{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/BDG_LOGO.png\" alt=\"drawing\" align=\"right\" width=\"200\"/>\n",
    "\n",
    "# H2020 RIA BigDataGrapes - Predictive Data Analytics (T4.3)\n",
    "\n",
    "### This pilot is described in the deliverable D4.3 (Pilot 5). \n",
    "\n",
    "The specific goal of the price prediction is to develop a software module that allows to predict the future price of specific goods in the grapes and wines supply chain. Starting from past observations of the price of different agro/food items, we build a machine learning pipeline that allows us to experiment with several prediction solutions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from random import sample   \n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm import tqdm_notebook\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(rc={'figure.figsize':(14,8)})\n",
    "# Adjusting the size of matplotlib\n",
    "\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# itens for test\n",
    "test_size = 0.3\n",
    "\n",
    "# choose a number of time steps\n",
    "n_steps = 7\n",
    "\n",
    "# metric\n",
    "loss_function=\"mse\"\n",
    "\n",
    "# epochs & batches\n",
    "epochs = 1500\n",
    "batch_size = 32\n",
    "optimizer = 'adam'\n",
    "neurons = 150\n",
    "\n",
    "\n",
    "# \n",
    "dict_settings['nn_configurations'] = {\n",
    "    \"n_steps\":n_steps\n",
    "    , \"loss_function\":loss_function\n",
    "    , \"epochs\":epochs\n",
    "    , \"batch_size\":batch_size\n",
    "    , \"optimizer\":optimizer\n",
    "    , \"neurons\":neurons\n",
    "}\n",
    "\n",
    "# settings of the experiment\n",
    "dict_settings = {\n",
    "    \"nn_configurations\": {},\n",
    "    \"constraints\": {},\n",
    "    \"product_name_id_mapping\": {},\n",
    "}\n",
    "\n",
    "# lst of columns to report\n",
    "lst_columns_to_report = ['model_name', 'mean_squared_error', 'root_mean_squared_error', 'mean_absolute_error', 'epochs', \"neurons\", \"test_size\", \"n_steps\", \"max_sequential_nan\", \"minimum_temporal_points\"]\n",
    "datetime_column_name = \"date\"\n",
    "\n",
    "\n",
    "## General Data Constraints\n",
    "max_sequential_nan = 7\n",
    "minimum_temporal_points = 50\n",
    "\n",
    "dict_settings['constraints'] = {\n",
    "        \"max_sequential_nan\": max_sequential_nan,\n",
    "        \"minimum_temporal_points\":minimum_temporal_points\n",
    "} \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Dataset\n",
    "\n",
    "We build our datasets starting from the open data published by the governments. The data used are collected from the Hellenic Food Market, the European Commission and the Food and Agriculture Organization of the United Nations. The dataset consists of a collection of daily observations of prices for a variety of products available in different countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all products 432\n",
      "after min points filter out 262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after missed dates 14\n"
     ]
    }
   ],
   "source": [
    "def fill_foward_missing_dates(df_product):\n",
    "  \n",
    "    # reindexing as datetime\n",
    "    df_product[datetime_column_name] = pd.to_datetime(df_product[datetime_column_name])\n",
    "    df_product = df_product.set_index(\"date\", drop=True)\n",
    "    \n",
    "    # adding the missing datetime intervals\n",
    "    df_product = df_product.asfreq('D')\n",
    "    \n",
    "    # foward filling\n",
    "    df_product = df_product.fillna(method='ffill')\n",
    "\n",
    "    # reset index: avoid datetime index\n",
    "    return df_product.reset_index()\n",
    "\n",
    "\n",
    "# check for a products if it has no more than a limit of sequencial missing information by day\n",
    "def check_product_time_series(df_product):\n",
    "    lst_intervals = [(dt2 - dt1).days if not pd.isna(dt1) else 0 for dt2, dt1 in zip(df_product[datetime_column_name], df_product[datetime_column_name].shift(1))]\n",
    "\n",
    "    if any(x > max_sequential_nan for x in lst_intervals):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def filter_out_products_without_min_temporal(df):\n",
    "    # keep only products with a good amout of data over the time\n",
    "    df_temporal_points = df.drop_duplicates(subset=[\"product\", \"priceStringDate\"]).groupby(['product']).size().reset_index(name='counts').sort_values('counts', ascending=False)\n",
    "    df_temporal_points = df_temporal_points[df_temporal_points['counts'] > minimum_temporal_points]\n",
    "\n",
    "    # what are these products\n",
    "    lst_products = df_temporal_points['product'].unique()\n",
    "    \n",
    "    # filter out \n",
    "    df = df[df['product'].isin(lst_products)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def group_price_by_date_and_product(df_data):\n",
    "    # group the data by product and date \n",
    "    df_data = df_data.groupby(by=[datetime_column_name, \"product\"]).agg([\"mean\", \"min\", \"max\"]).reset_index()\n",
    "    \n",
    "    # flatten the columns\n",
    "    df_data.columns = [' '.join(col).strip() for col in df_data.columns.values]\n",
    "    df_data.columns = [col.replace(' ', '_') if \"price\" in col else col for col in df_data.columns.values]\n",
    "    \n",
    "    # return the values\n",
    "    return df_data\n",
    "\n",
    "df_temporal_points = None\n",
    "df_debug = None\n",
    "\n",
    "def load_data():\n",
    "    \n",
    "    global df_temporal_points, df_debug\n",
    "    \n",
    "    # reading the whole dataset (multi-product)\n",
    "    df = pd.read_csv(\"../datasets/food_dataset.csv\", parse_dates=[\"priceStringDate\"])\n",
    "    \n",
    "    print(\"all products\", len(df['product'].unique()))\n",
    "    df = filter_out_products_without_min_temporal(df)\n",
    "    \n",
    "    \n",
    "    # rename to the default date column \n",
    "    df = df.rename(columns={\"priceStringDate\": datetime_column_name})\n",
    "    \n",
    "    # sort the data by time\n",
    "    df = df.sort_values(by=datetime_column_name, ascending=True)\n",
    "    \n",
    "    # fill missing country information\n",
    "    df['country'].fillna('ND', inplace=True)\n",
    "    \n",
    "    # group the data\n",
    "    df = group_price_by_date_and_product(df)\n",
    "    df_debug = df\n",
    "    \n",
    "    lst_products = df['product'].unique()\n",
    "    print(\"after min points filter out\", len(lst_products))\n",
    "\n",
    "    # check products time series\n",
    "    for product_name in lst_products:\n",
    "        # filter by product\n",
    "        df_product = df[df['product']==product_name]\n",
    "        \n",
    "        # check timeseties \n",
    "        istimeseries_ok = check_product_time_series(df_product)\n",
    "        \n",
    "        if not istimeseries_ok:\n",
    "            # if it is not filter out\n",
    "            df = df[df['product']!=product_name]\n",
    "        else:\n",
    "            # fill foward \n",
    "            df_product = fill_foward_missing_dates(df_product)\n",
    "            \n",
    "            # filter out\n",
    "            df = df[df['product']!=product_name]\n",
    "            \n",
    "            # put the new one\n",
    "            df = pd.concat([df, df_product])\n",
    "            \n",
    "    print(\"after missed dates\", len(df['product'].unique()))\n",
    "    \n",
    "    # reset the index\n",
    "    df = df.reset_index()\n",
    "    # return the dataframe\n",
    "    return df \n",
    "    \n",
    "\n",
    "df_data = load_data()\n",
    "df_data.to_csv(\"../datasets/df_data_forward_agg.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>product</th>\n",
       "      <th>price_mean</th>\n",
       "      <th>price_min</th>\n",
       "      <th>price_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22325</th>\n",
       "      <td>1295</td>\n",
       "      <td>2014-01-06</td>\n",
       "      <td>crude olive-pomace oil (from 5 to 10°)</td>\n",
       "      <td>77.803333</td>\n",
       "      <td>75.13</td>\n",
       "      <td>79.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35085</th>\n",
       "      <td>443</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>virgin olive oil (up to 2°)</td>\n",
       "      <td>186.519333</td>\n",
       "      <td>165.00</td>\n",
       "      <td>215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26302</th>\n",
       "      <td>1869</td>\n",
       "      <td>2015-08-03</td>\n",
       "      <td>extra virgin olive oil (up to 0,8°)</td>\n",
       "      <td>547.126154</td>\n",
       "      <td>330.00</td>\n",
       "      <td>2934.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>1910</td>\n",
       "      <td>1996-03-24</td>\n",
       "      <td>pig carcases 55% or more but less than 60% meat</td>\n",
       "      <td>150.320667</td>\n",
       "      <td>134.39</td>\n",
       "      <td>166.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32895</th>\n",
       "      <td>1656</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>refined olive oil (up to 0,3°)</td>\n",
       "      <td>268.646667</td>\n",
       "      <td>248.00</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index       date                                          product  \\\n",
       "22325   1295 2014-01-06           crude olive-pomace oil (from 5 to 10°)   \n",
       "35085    443 2011-09-07                      virgin olive oil (up to 2°)   \n",
       "26302   1869 2015-08-03              extra virgin olive oil (up to 0,8°)   \n",
       "1910    1910 1996-03-24  pig carcases 55% or more but less than 60% meat   \n",
       "32895   1656 2015-01-02                   refined olive oil (up to 0,3°)   \n",
       "\n",
       "       price_mean  price_min  price_max  \n",
       "22325   77.803333      75.13       79.5  \n",
       "35085  186.519333     165.00      215.0  \n",
       "26302  547.126154     330.00     2934.0  \n",
       "1910   150.320667     134.39      166.8  \n",
       "32895  268.646667     248.00      284.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nn_configurations': {'n_steps': 7,\n",
       "  'loss_function': 'mse',\n",
       "  'epochs': 1500,\n",
       "  'batch_size': 32,\n",
       "  'optimizer': 'adam',\n",
       "  'neurons': 150},\n",
       " 'constraints': {'max_sequential_nan': 7, 'minimum_temporal_points': 50},\n",
       " 'product_name_id_mapping': {'pig carcases 55% or more but less than 60% meat': 1,\n",
       "  'piglet': 2,\n",
       "  'crude olive-pomace oil (from 5 to 10°)': 3,\n",
       "  'extra virgin olive oil (up to 0,8°)': 4,\n",
       "  'lampante olive oil (2°)': 5,\n",
       "  'refined olive oil (up to 0,3°)': 6,\n",
       "  'virgin olive oil (up to 2°)': 7,\n",
       "  'refined olive-pomace oil (up to 0.3°)': 8,\n",
       "  'soft wheat - milling wheat delivered to port - grain delivered to a port silo by train or truck or barge': 9,\n",
       "  'maize - maize deliver to first customer - silo or processing plant - on truck or other transport means': 10,\n",
       "  'pig carcases with 60% or more meat': 11,\n",
       "  'πατάτες εγχ.': 12,\n",
       "  'μήλα ντελίσιους πιλαφά τριπολεως': 13,\n",
       "  'πατάτες εισαγ': 14}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 1\n",
    "dict_map_name_id = {}\n",
    "\n",
    "for p in df_data['product'].unique():\n",
    "    dict_map_name_id.update({p: idx})\n",
    "    idx = idx + 1\n",
    "\n",
    "dict_settings['product_name_id_mapping'] = dict_map_name_id\n",
    "dict_settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliar methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "def plot_price_by_country(df_product):\n",
    "    #try: \n",
    "    # setup the plot\n",
    "    fig = px.line(df_product, x=datetime_column_name, y=\"price_mean\",width=800, height=400).update_traces(mode='lines+markers')\n",
    "    fig.update_layout(title_text='Product Price by Country: {0}'.format(product_name),\n",
    "                      xaxis_rangeslider_visible=True)\n",
    "    # display\n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model\n",
    "\n",
    "we employ time series, i.e., sequences of per-product price observations, to learn a machine learning system that allows us to predict the future price of the product, given an historical time window. Time series prediction is a well-known task that is commonly addressed using neural networks. We employ Long Short-term memory (LSTM) networks to address this task. LSTM is a powerful RNN architecture with important application in time series prediction. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \n",
    "    global neurons, n_steps, optimizer, loss_function\n",
    "    n_features = 1\n",
    "    \n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(neurons, activation='relu'\n",
    "                   , input_shape=(n_steps, n_features)\n",
    "                   , return_sequences=False))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=optimizer, loss=loss_function)\n",
    "    \n",
    "    # patient early stopping\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)\n",
    "    \n",
    "    return model, es\n",
    "\n",
    "\n",
    "# split a univariate sequence into samples\n",
    "\n",
    "def compute_scores(y_train, y_true, y_pred, reshape=True):\n",
    "    # compute scores\n",
    "    dic_result = {}\n",
    "    dic_result[\"mean_squared_error\"] = mean_squared_error(y_true, y_pred)\n",
    "    dic_result[\"root_mean_squared_error\"] = math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    dic_result[\"mean_absolute_error\"] = mean_absolute_error(y_true, y_pred)\n",
    "    dic_result[\"y_train\"] = y_train.reshape(1,-1).tolist() if reshape else y_train.tolist()\n",
    "    dic_result[\"y_true\"] = y_true.reshape(1,-1).tolist() if reshape else y_true.tolist()\n",
    "    dic_result[\"y_pred\"] = y_pred.reshape(1,-1).tolist() if reshape else y_pred.tolist()\n",
    "    return dic_result\n",
    "\n",
    "\n",
    "# report metric results\n",
    "def get_dataframe_results(lst_results):\n",
    "    d = {}\n",
    "    # for each column\n",
    "    for k in lst_results[0].keys():\n",
    "        d[k] = tuple(d[k] for d in lst_results)\n",
    "\n",
    "    # show the results\n",
    "    df_results = pd.DataFrame.from_dict(d) # [lst_columns_to_report]\n",
    "    df_results.sort_values(by=['root_mean_squared_error'])\n",
    "    return df_results\n",
    "\n",
    "\n",
    "\n",
    "def univariate_lstm_with_test_set(df_data, col_value):\n",
    "    # global variable\n",
    "    global test_size, n_steps, optimizer, loss_function\n",
    "    \n",
    "    # define input sequence\n",
    "    raw_seq = df_data[col_value].tolist()\n",
    "    raw_seq = np.array(raw_seq).reshape(len(raw_seq),1)\n",
    "    raw_seq = raw_seq \n",
    "    \n",
    "    # test size\n",
    "    if test_size < 1:\n",
    "        test_seq_len = int(len(raw_seq) * test_size)\n",
    "    else:\n",
    "        test_seq_len = test_size\n",
    "    \n",
    "    # scale for the training data\n",
    "    raw_seq_seen_in_training = raw_seq[:-test_seq_len]\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(raw_seq_seen_in_training)\n",
    "    \n",
    "    # transform the whole data (inclusing the test set)\n",
    "    scaled_seq = scaler.transform(raw_seq)\n",
    "    \n",
    "    # split into samples\n",
    "    X, y = split_sequence(scaled_seq, n_steps)\n",
    "    \n",
    "    # reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "    n_features = 1\n",
    "    X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "    \n",
    "    # split into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_seq_len, shuffle=False)\n",
    "    \n",
    "    # create the model\n",
    "    model, es = create_model()\n",
    "    \n",
    "    # fit model\n",
    "    history = model.fit(X\n",
    "                        , y\n",
    "                        , epochs=epochs\n",
    "                        , batch_size=batch_size\n",
    "                        , verbose=1\n",
    "                        , shuffle=False\n",
    "                        , validation_data=(X, y)\n",
    "                        , callbacks=[es]\n",
    "                       )\n",
    "\n",
    "    # predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    # inverse transform\n",
    "    y_train = scaler.inverse_transform(y_train)\n",
    "    y_pred = scaler.inverse_transform(y_pred)\n",
    "    y_test = raw_seq[-test_seq_len:]\n",
    "    \n",
    "    # evaluate the model\n",
    "    # scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "    scores = compute_scores(y_train,y_test, y_pred)\n",
    "    \n",
    "    # return model, history, scores, y_pred\n",
    "    return scores\n",
    "\n",
    "\n",
    "def log_test_result(model_name, product_name, scores, features=\"TimeSeries\"):\n",
    "    dic_result = {\"model_name\": model_name\n",
    "                  , \"product_name\": product_name\n",
    "                  , \"test_size\": test_size\n",
    "                  , \"n_steps\": n_steps\n",
    "                  , \"features\": features\n",
    "                  , \"neurons\": neurons\n",
    "                  , \"drop_out\": \"\"\n",
    "                  , \"epochs\": epochs\n",
    "                  , \"max_sequential_nan\": max_sequential_nan\n",
    "                  , \"minimum_temporal_points\": minimum_temporal_points}\n",
    "\n",
    "    dic_result.update(scores)\n",
    "    return dic_result\n",
    "\n",
    "\n",
    "# Adjusting the size of matplotlib\n",
    "resolution = (14,6)\n",
    "\n",
    "def plot_forecast(model_name, dict_results):\n",
    "    y_train = dict_results['y_train'][0]\n",
    "    y_test = dict_results['y_true'][0]\n",
    "    y_pred = dict_results['y_pred'][0]\n",
    "    \n",
    "    # Creates pandas DataFrame. \n",
    "    df_plot = pd.DataFrame({'forecast': [np.nan] * len(y_train) + list(y_pred), \n",
    "               'price': list(np.reshape(y_train, len(y_train))) + list(y_test)}) \n",
    "    \n",
    "    df_plot['price'].plot(figsize=resolution, title='Price ({0})'.format(model_name), grid=True)\n",
    "    df_plot['forecast'].plot()\n",
    "    plt.legend(loc=1)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "doExperiment = True\n",
    "if doExperiment:\n",
    "    # load the dataset\n",
    "    df_data = load_data()\n",
    "\n",
    "    # list of products \n",
    "    lst_all_products = list(df_data['product'].unique())\n",
    "\n",
    "    # prediction results list\n",
    "    lst_results = []\n",
    "\n",
    "    for product_name in tqdm_notebook(lst_all_products): \n",
    "        # model name\n",
    "        model_name = \"lstm_fforward\"\n",
    "\n",
    "        # filter by product\n",
    "        df_product = df_data[df_data['product']==product_name]\n",
    "\n",
    "        # perform the prediction\n",
    "        print(\"product_name\", product_name)\n",
    "        scores = univariate_lstm_with_test_set(df_product, \"price_mean\")\n",
    "        result_by_product = log_test_result(model_name, product_name, scores)\n",
    "\n",
    "        # plot the results\n",
    "        # plot_forecast(model_name, result_by_product)\n",
    "\n",
    "        # log the results\n",
    "        lst_results.append(result_by_product)\n",
    "\n",
    "    # save results\n",
    "    df_results = get_dataframe_results(lst_results)\n",
    "    df_results.to_csv(\"../results/results_lstm_fforward.csv\", index=False, encoding = 'utf-8')\n",
    "    df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train and Save the models for the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def univariate_lstm_save_models(df_data, col_value):\n",
    "    # global variable\n",
    "    global test_size, n_steps, optimizer, loss_function\n",
    "    \n",
    "    # define input sequence\n",
    "    raw_seq = df_data[col_value].tolist()\n",
    "    raw_seq = np.array(raw_seq).reshape(len(raw_seq),1)\n",
    "    raw_seq = raw_seq \n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(raw_seq)\n",
    "    \n",
    "    # transform the whole data (inclusing the test set)\n",
    "    scaled_seq = scaler.transform(raw_seq)\n",
    "    \n",
    "    # split into samples\n",
    "    X, y = split_sequence(scaled_seq, n_steps)\n",
    "    \n",
    "    # reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "    n_features = 1\n",
    "    X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "    \n",
    "    # define the model\n",
    "    create_model()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(X\n",
    "                        , y\n",
    "                        , epochs=epochs\n",
    "                        , batch_size=batch_size\n",
    "                        , verbose=0\n",
    "                        , shuffle=False\n",
    "                        , callbacks=[es])\n",
    "    \n",
    "    # return the model\n",
    "    return scaler, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%time\n",
    "# load the dataset\n",
    "df_data = load_data()\n",
    "\n",
    "# prediction results list\n",
    "dict_models = {}\n",
    "\n",
    "# list of products \n",
    "lst_all_products = list(df_data['product'].unique())\n",
    "\n",
    "for product_name in tqdm_notebook(lst_all_products):\n",
    "    # model name\n",
    "    model_name = \"lstm_fforward\"\n",
    "    \n",
    "    # filter by product\n",
    "    df_product = df_data[df_data['product']==product_name]\n",
    "    \n",
    "    # perform the prediction\n",
    "    # print(\"product_name\", product_name)\n",
    "    scaler, model = univariate_lstm_save_models(df_product, \"price_mean\")\n",
    "    \n",
    "    mapping_name_id = dict_settings[\"product_name_id_mapping\"]\n",
    "    product_id = mapping_name_id[product_name]\n",
    "    \n",
    "    # save model\n",
    "    model.save(\"models/product_id_{0}.h5\".format(product_id))\n",
    "    # pickle.dump(model, open(\"models/product_id_{0}.pkl\".format(product_id), 'wb'))\n",
    "    \n",
    "    # save scaler\n",
    "    pickle.dump(scaler, open('scalers/product_id_{0}.pkl'.format(product_id), 'wb'))\n",
    "\n",
    "    \n",
    "with open('settings.json', 'w', encoding='utf8') as outfile:\n",
    "    json.dump(dict_settings, outfile, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Average Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def baseline_moving_average(df_product, col_value):\n",
    "    # global variable\n",
    "    global test_size\n",
    "    n_steps = 15\n",
    "\n",
    "    x = df_product[col_value]\n",
    "    test_seq_len = int(test_size * len(x))\n",
    "    \n",
    "    y_test = x[-test_seq_len:]\n",
    "    y_train = x[:-test_seq_len]\n",
    "    \n",
    "    x = x[-(test_seq_len+n_steps-1):]\n",
    "    y_pred = pd.Series(x).rolling(window=n_steps).mean().iloc[n_steps-1:].values    \n",
    "    \n",
    "    # evaluate the model\n",
    "    scores = compute_scores(y_train, y_test, y_pred, reshape=False)\n",
    "    \n",
    "    # return model, history, scores, y_pred\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 µs, sys: 1e+03 ns, total: 12 µs\n",
      "Wall time: 26.5 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: TqdmDeprecationWarning:\n",
      "\n",
      "This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2c397e644147e7b7d6000632599101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=14), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7361 3154 3154\n",
      "7361 3154 3154\n",
      "2383 1020 1020\n",
      "2383 1020 1020\n",
      "2383 1020 1020\n",
      "2383 1020 1020\n",
      "2383 1020 1020\n",
      "2373 1016 1016\n",
      "1638 701 701\n",
      "1633 699 699\n",
      "1481 634 634\n",
      "433 185 185\n",
      "89 38 38\n",
      "104 44 44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "load the dataset\n",
    "df_data = load_data()\n",
    "\n",
    "# prediction results list\n",
    "lst_results_bas_mavg = []\n",
    "\n",
    "# list of products \n",
    "lst_all_products = list(df_data['product'].unique())\n",
    "\n",
    "for product_name in tqdm_notebook(lst_all_products): \n",
    "    # model name\n",
    "    model_name = \"moving_avg\"\n",
    "    \n",
    "    # filter by product\n",
    "    df_product = df_data[df_data['product']==product_name]\n",
    "    \n",
    "    # perform the prediction\n",
    "    scores = baseline_moving_average(df_product, \"price_mean\")\n",
    "    result_by_product = log_test_result(model_name, product_name, scores)\n",
    "    \n",
    "    # log the results\n",
    "    lst_results_bas_mavg.append(result_by_product)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>product_name</th>\n",
       "      <th>test_size</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>features</th>\n",
       "      <th>neurons</th>\n",
       "      <th>drop_out</th>\n",
       "      <th>epochs</th>\n",
       "      <th>max_sequential_nan</th>\n",
       "      <th>minimum_temporal_points</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>y_train</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>moving_avg</td>\n",
       "      <td>pig carcases 55% or more but less than 60% meat</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7</td>\n",
       "      <td>TimeSeries</td>\n",
       "      <td>150</td>\n",
       "      <td></td>\n",
       "      <td>1500</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>2.542280</td>\n",
       "      <td>1.594453</td>\n",
       "      <td>1.146712</td>\n",
       "      <td>[120.34833333333336, 120.34833333333336, 120.3...</td>\n",
       "      <td>[148.48392857142858, 148.48392857142858, 148.4...</td>\n",
       "      <td>[148.1661190476191, 148.26300000000006, 148.35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>moving_avg</td>\n",
       "      <td>piglet</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7</td>\n",
       "      <td>TimeSeries</td>\n",
       "      <td>150</td>\n",
       "      <td></td>\n",
       "      <td>1500</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>0.585300</td>\n",
       "      <td>0.765049</td>\n",
       "      <td>0.566608</td>\n",
       "      <td>[32.434, 32.434, 32.434, 32.434, 32.434, 32.43...</td>\n",
       "      <td>[42.997368421052634, 42.997368421052634, 42.99...</td>\n",
       "      <td>[42.92880701754386, 42.933157894736844, 42.937...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>moving_avg</td>\n",
       "      <td>crude olive-pomace oil (from 5 to 10°)</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7</td>\n",
       "      <td>TimeSeries</td>\n",
       "      <td>150</td>\n",
       "      <td></td>\n",
       "      <td>1500</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>7.769820</td>\n",
       "      <td>2.787440</td>\n",
       "      <td>1.641198</td>\n",
       "      <td>[68.64, 68.64, 68.64, 68.64, 68.64, 68.64, 68....</td>\n",
       "      <td>[128.03333333333333, 128.03333333333333, 128.0...</td>\n",
       "      <td>[126.77533333333331, 127.03111111111109, 127.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>moving_avg</td>\n",
       "      <td>extra virgin olive oil (up to 0,8°)</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7</td>\n",
       "      <td>TimeSeries</td>\n",
       "      <td>150</td>\n",
       "      <td></td>\n",
       "      <td>1500</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>302.150777</td>\n",
       "      <td>17.382485</td>\n",
       "      <td>11.508986</td>\n",
       "      <td>[235.6971428571428, 235.6971428571428, 235.697...</td>\n",
       "      <td>[385.55142857142863, 385.55142857142863, 385.5...</td>\n",
       "      <td>[392.83275132275145, 386.5322539682541, 380.23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>moving_avg</td>\n",
       "      <td>lampante olive oil (2°)</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7</td>\n",
       "      <td>TimeSeries</td>\n",
       "      <td>150</td>\n",
       "      <td></td>\n",
       "      <td>1500</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>21.417568</td>\n",
       "      <td>4.627912</td>\n",
       "      <td>3.207749</td>\n",
       "      <td>[156.92727272727276, 156.92727272727276, 156.9...</td>\n",
       "      <td>[318.1283333333334, 318.1283333333334, 318.128...</td>\n",
       "      <td>[309.01504273504275, 310.71005982905984, 312.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>moving_avg</td>\n",
       "      <td>refined olive oil (up to 0,3°)</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7</td>\n",
       "      <td>TimeSeries</td>\n",
       "      <td>150</td>\n",
       "      <td></td>\n",
       "      <td>1500</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>21.982644</td>\n",
       "      <td>4.688565</td>\n",
       "      <td>3.220911</td>\n",
       "      <td>[179.3457142857143, 179.3457142857143, 179.345...</td>\n",
       "      <td>[329.33666666666664, 329.33666666666664, 329.3...</td>\n",
       "      <td>[331.1264444444445, 330.6766666666668, 330.226...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>moving_avg</td>\n",
       "      <td>virgin olive oil (up to 2°)</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7</td>\n",
       "      <td>TimeSeries</td>\n",
       "      <td>150</td>\n",
       "      <td></td>\n",
       "      <td>1500</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>178.928482</td>\n",
       "      <td>13.376415</td>\n",
       "      <td>9.389668</td>\n",
       "      <td>[185.5271428571429, 185.5271428571429, 185.527...</td>\n",
       "      <td>[331.6014285714286, 331.6014285714286, 331.601...</td>\n",
       "      <td>[345.15738095238083, 341.59789285714277, 338.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>moving_avg</td>\n",
       "      <td>refined olive-pomace oil (up to 0.3°)</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7</td>\n",
       "      <td>TimeSeries</td>\n",
       "      <td>150</td>\n",
       "      <td></td>\n",
       "      <td>1500</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>13.149663</td>\n",
       "      <td>3.626246</td>\n",
       "      <td>2.452424</td>\n",
       "      <td>[113.88333333333333, 113.88333333333333, 113.8...</td>\n",
       "      <td>[184.92166666666665, 184.92166666666665, 184.9...</td>\n",
       "      <td>[174.55388888888882, 175.59866666666662, 176.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>moving_avg</td>\n",
       "      <td>soft wheat - milling wheat delivered to port -...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7</td>\n",
       "      <td>TimeSeries</td>\n",
       "      <td>150</td>\n",
       "      <td></td>\n",
       "      <td>1500</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>8.578365</td>\n",
       "      <td>2.928885</td>\n",
       "      <td>1.962174</td>\n",
       "      <td>[223.65, 223.65, 223.65, 223.65, 223.65, 223.6...</td>\n",
       "      <td>[161.36, 161.36, 161.36, 161.36, 161.36, 161.3...</td>\n",
       "      <td>[161.50933333333333, 161.49033333333333, 161.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>moving_avg</td>\n",
       "      <td>maize - maize deliver to first customer - silo...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7</td>\n",
       "      <td>TimeSeries</td>\n",
       "      <td>150</td>\n",
       "      <td></td>\n",
       "      <td>1500</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>7.363897</td>\n",
       "      <td>2.713650</td>\n",
       "      <td>1.847160</td>\n",
       "      <td>[218.85, 218.85, 218.85, 218.85, 218.85, 218.8...</td>\n",
       "      <td>[160.49, 160.49, 160.49, 160.49, 160.49, 159.1...</td>\n",
       "      <td>[159.58444444444442, 159.58822222222219, 159.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>moving_avg</td>\n",
       "      <td>pig carcases with 60% or more meat</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7</td>\n",
       "      <td>TimeSeries</td>\n",
       "      <td>150</td>\n",
       "      <td></td>\n",
       "      <td>1500</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>3.057946</td>\n",
       "      <td>1.748698</td>\n",
       "      <td>1.141907</td>\n",
       "      <td>[177.28705882352938, 177.28705882352938, 177.2...</td>\n",
       "      <td>[144.63279999999997, 144.63279999999997, 144.6...</td>\n",
       "      <td>[146.92639999999994, 146.6574666666666, 146.38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>moving_avg</td>\n",
       "      <td>πατάτες εγχ.</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7</td>\n",
       "      <td>TimeSeries</td>\n",
       "      <td>150</td>\n",
       "      <td></td>\n",
       "      <td>1500</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.014851</td>\n",
       "      <td>0.007539</td>\n",
       "      <td>[0.38, 0.38, 0.38, 0.34, 0.34, 0.34, 0.34, 0.3...</td>\n",
       "      <td>[0.52, 0.52, 0.52, 0.52, 0.52, 0.52, 0.52, 0.5...</td>\n",
       "      <td>[0.5079999999999998, 0.5093333333333331, 0.510...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>moving_avg</td>\n",
       "      <td>μήλα ντελίσιους πιλαφά τριπολεως</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7</td>\n",
       "      <td>TimeSeries</td>\n",
       "      <td>150</td>\n",
       "      <td></td>\n",
       "      <td>1500</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>moving_avg</td>\n",
       "      <td>πατάτες εισαγ</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7</td>\n",
       "      <td>TimeSeries</td>\n",
       "      <td>150</td>\n",
       "      <td></td>\n",
       "      <td>1500</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.007035</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>[0.44, 0.44, 0.44, 0.44, 0.44, 0.44, 0.46, 0.4...</td>\n",
       "      <td>[0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.5...</td>\n",
       "      <td>[0.5499999999999999, 0.5499999999999999, 0.549...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_name                                       product_name  test_size  \\\n",
       "0   moving_avg    pig carcases 55% or more but less than 60% meat        0.3   \n",
       "1   moving_avg                                             piglet        0.3   \n",
       "2   moving_avg             crude olive-pomace oil (from 5 to 10°)        0.3   \n",
       "3   moving_avg                extra virgin olive oil (up to 0,8°)        0.3   \n",
       "4   moving_avg                            lampante olive oil (2°)        0.3   \n",
       "5   moving_avg                     refined olive oil (up to 0,3°)        0.3   \n",
       "6   moving_avg                        virgin olive oil (up to 2°)        0.3   \n",
       "7   moving_avg              refined olive-pomace oil (up to 0.3°)        0.3   \n",
       "8   moving_avg  soft wheat - milling wheat delivered to port -...        0.3   \n",
       "9   moving_avg  maize - maize deliver to first customer - silo...        0.3   \n",
       "10  moving_avg                 pig carcases with 60% or more meat        0.3   \n",
       "11  moving_avg                                       πατάτες εγχ.        0.3   \n",
       "12  moving_avg                   μήλα ντελίσιους πιλαφά τριπολεως        0.3   \n",
       "13  moving_avg                                      πατάτες εισαγ        0.3   \n",
       "\n",
       "    n_steps    features  neurons drop_out  epochs  max_sequential_nan  \\\n",
       "0         7  TimeSeries      150             1500                   7   \n",
       "1         7  TimeSeries      150             1500                   7   \n",
       "2         7  TimeSeries      150             1500                   7   \n",
       "3         7  TimeSeries      150             1500                   7   \n",
       "4         7  TimeSeries      150             1500                   7   \n",
       "5         7  TimeSeries      150             1500                   7   \n",
       "6         7  TimeSeries      150             1500                   7   \n",
       "7         7  TimeSeries      150             1500                   7   \n",
       "8         7  TimeSeries      150             1500                   7   \n",
       "9         7  TimeSeries      150             1500                   7   \n",
       "10        7  TimeSeries      150             1500                   7   \n",
       "11        7  TimeSeries      150             1500                   7   \n",
       "12        7  TimeSeries      150             1500                   7   \n",
       "13        7  TimeSeries      150             1500                   7   \n",
       "\n",
       "    minimum_temporal_points  mean_squared_error  root_mean_squared_error  \\\n",
       "0                        50            2.542280                 1.594453   \n",
       "1                        50            0.585300                 0.765049   \n",
       "2                        50            7.769820                 2.787440   \n",
       "3                        50          302.150777                17.382485   \n",
       "4                        50           21.417568                 4.627912   \n",
       "5                        50           21.982644                 4.688565   \n",
       "6                        50          178.928482                13.376415   \n",
       "7                        50           13.149663                 3.626246   \n",
       "8                        50            8.578365                 2.928885   \n",
       "9                        50            7.363897                 2.713650   \n",
       "10                       50            3.057946                 1.748698   \n",
       "11                       50            0.000221                 0.014851   \n",
       "12                       50            0.000000                 0.000000   \n",
       "13                       50            0.000049                 0.007035   \n",
       "\n",
       "    mean_absolute_error                                            y_train  \\\n",
       "0              1.146712  [120.34833333333336, 120.34833333333336, 120.3...   \n",
       "1              0.566608  [32.434, 32.434, 32.434, 32.434, 32.434, 32.43...   \n",
       "2              1.641198  [68.64, 68.64, 68.64, 68.64, 68.64, 68.64, 68....   \n",
       "3             11.508986  [235.6971428571428, 235.6971428571428, 235.697...   \n",
       "4              3.207749  [156.92727272727276, 156.92727272727276, 156.9...   \n",
       "5              3.220911  [179.3457142857143, 179.3457142857143, 179.345...   \n",
       "6              9.389668  [185.5271428571429, 185.5271428571429, 185.527...   \n",
       "7              2.452424  [113.88333333333333, 113.88333333333333, 113.8...   \n",
       "8              1.962174  [223.65, 223.65, 223.65, 223.65, 223.65, 223.6...   \n",
       "9              1.847160  [218.85, 218.85, 218.85, 218.85, 218.85, 218.8...   \n",
       "10             1.141907  [177.28705882352938, 177.28705882352938, 177.2...   \n",
       "11             0.007539  [0.38, 0.38, 0.38, 0.34, 0.34, 0.34, 0.34, 0.3...   \n",
       "12             0.000000  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "13             0.001061  [0.44, 0.44, 0.44, 0.44, 0.44, 0.44, 0.46, 0.4...   \n",
       "\n",
       "                                               y_true  \\\n",
       "0   [148.48392857142858, 148.48392857142858, 148.4...   \n",
       "1   [42.997368421052634, 42.997368421052634, 42.99...   \n",
       "2   [128.03333333333333, 128.03333333333333, 128.0...   \n",
       "3   [385.55142857142863, 385.55142857142863, 385.5...   \n",
       "4   [318.1283333333334, 318.1283333333334, 318.128...   \n",
       "5   [329.33666666666664, 329.33666666666664, 329.3...   \n",
       "6   [331.6014285714286, 331.6014285714286, 331.601...   \n",
       "7   [184.92166666666665, 184.92166666666665, 184.9...   \n",
       "8   [161.36, 161.36, 161.36, 161.36, 161.36, 161.3...   \n",
       "9   [160.49, 160.49, 160.49, 160.49, 160.49, 159.1...   \n",
       "10  [144.63279999999997, 144.63279999999997, 144.6...   \n",
       "11  [0.52, 0.52, 0.52, 0.52, 0.52, 0.52, 0.52, 0.5...   \n",
       "12  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "13  [0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.5...   \n",
       "\n",
       "                                               y_pred  \n",
       "0   [148.1661190476191, 148.26300000000006, 148.35...  \n",
       "1   [42.92880701754386, 42.933157894736844, 42.937...  \n",
       "2   [126.77533333333331, 127.03111111111109, 127.2...  \n",
       "3   [392.83275132275145, 386.5322539682541, 380.23...  \n",
       "4   [309.01504273504275, 310.71005982905984, 312.4...  \n",
       "5   [331.1264444444445, 330.6766666666668, 330.226...  \n",
       "6   [345.15738095238083, 341.59789285714277, 338.0...  \n",
       "7   [174.55388888888882, 175.59866666666662, 176.6...  \n",
       "8   [161.50933333333333, 161.49033333333333, 161.4...  \n",
       "9   [159.58444444444442, 159.58822222222219, 159.5...  \n",
       "10  [146.92639999999994, 146.6574666666666, 146.38...  \n",
       "11  [0.5079999999999998, 0.5093333333333331, 0.510...  \n",
       "12  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n",
       "13  [0.5499999999999999, 0.5499999999999999, 0.549...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bas2 = get_dataframe_results(lst_results_bas_mavg)\n",
    "df_bas2.to_csv(\"../results/results_bas_moving_avg.csv\", index=False, encoding = 'utf-8')\n",
    "df_bas2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
